# NeuroCity CUDA æ ¸å‡½æ•°ä½¿ç”¨æŒ‡å—

æœ¬æ–‡æ¡£æä¾›äº† NeuroCity é¡¹ç›®ä¸­æ‰€æœ‰ CUDA æ ¸å‡½æ•°çš„ä½¿ç”¨æŒ‡å—ç´¢å¼•ã€‚NeuroCity åŒ…å«å¤šä¸ªä¼˜åŒ–çš„ NeRF å®ç°ï¼Œæ¯ä¸ªéƒ½æœ‰ç‰¹å®šçš„ CUDA ä¼˜åŒ–ã€‚

## ğŸ“‹ CUDA æ”¯æŒæ¦‚è§ˆ

| æ¨¡å— | CUDA æ”¯æŒ | ä¸»è¦æ ¸å‡½æ•° | æ€§èƒ½æå‡ | æ–‡æ¡£é“¾æ¥ |
|------|-----------|------------|----------|----------|
| **SVRaster** | âœ… å®Œæ•´æ”¯æŒ | ç¨€ç–ä½“ç´ å…‰æ …åŒ–ã€è«é¡¿æ’åº | 16.7x | [SVRaster CUDA æŒ‡å—](src/nerfs/svraster/README_cn.md#cuda-æ ¸å‡½æ•°ä½¿ç”¨æŒ‡å—) |
| **Plenoxels** | âœ… å®Œæ•´æ”¯æŒ | ä½“ç´ é‡‡æ ·ã€ä¸‰çº¿æ€§æ’å€¼ã€çƒè°å‡½æ•° | 16.6x | [Plenoxels CUDA æŒ‡å—](src/nerfs/plenoxels/README_cn.md#cuda-æ ¸å‡½æ•°ä½¿ç”¨æŒ‡å—) |
| **InfNeRF** | âœ… å®Œæ•´æ”¯æŒ | å…«å‰æ ‘éå†ã€å“ˆå¸Œç¼–ç  | 16.8x | [InfNeRF CUDA æŒ‡å—](src/nerfs/inf_nerf/README_cn.md#cuda-æ ¸å‡½æ•°ä½¿ç”¨æŒ‡å—) |
| **Instant NGP** | âš ï¸ éƒ¨åˆ†æ”¯æŒ | å“ˆå¸Œç¼–ç ã€å¤šå±‚æ„ŸçŸ¥æœº | 10-20x | [Instant NGP æ–‡æ¡£](src/nerfs/instant_ngp/README_cn.md) |
| **Block-NeRF** | âš ï¸ éƒ¨åˆ†æ”¯æŒ | å—çº§é‡‡æ ·ã€ç©ºé—´åˆ†å‰² | 5-10x | [Block-NeRF æ–‡æ¡£](src/nerfs/block_nerf/README_cn.md) |
| **Mega-NeRF** | âš ï¸ éƒ¨åˆ†æ”¯æŒ | å¤§è§„æ¨¡åœºæ™¯é‡‡æ · | 5-10x | [Mega-NeRF æ–‡æ¡£](src/nerfs/mega_nerf/README_cn.md) |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè®¾ç½®

```bash
# æ£€æŸ¥ CUDA ç‰ˆæœ¬
nvcc --version

# éªŒè¯ PyTorch CUDA æ”¯æŒ
python -c "import torch; print(f'CUDA å¯ç”¨: {torch.cuda.is_available()}')"

# å®‰è£… CUDA å·¥å…·åŒ… (å¦‚æœéœ€è¦)
sudo apt-get install nvidia-cuda-toolkit
```

### 2. ç¼–è¯‘ CUDA æ‰©å±•

```bash
# ç¼–è¯‘æ‰€æœ‰ CUDA æ‰©å±•
python tools/build_cuda_extensions.py

# æˆ–åˆ†åˆ«ç¼–è¯‘å„ä¸ªæ¨¡å—
cd src/nerfs/svraster && python setup.py build_ext --inplace
cd src/nerfs/plenoxels && python setup.py build_ext --inplace
cd src/nerfs/inf_nerf && python setup.py build_ext --inplace
```

### 3. éªŒè¯ CUDA åŠŸèƒ½

```python
# éªŒè¯æ‰€æœ‰ CUDA æ ¸å‡½æ•°
from tools.verify_cuda_support import verify_all_cuda_modules

results = verify_all_cuda_modules()
for module, status in results.items():
    print(f"{module}: {'âœ… æ”¯æŒ' if status else 'âŒ ä¸æ”¯æŒ'}")
```

## ğŸ“– è¯¦ç»†æ–‡æ¡£

### SVRaster CUDA ä½¿ç”¨

SVRaster æä¾›äº†æœ€å®Œæ•´çš„ CUDA ä¼˜åŒ–ï¼ŒåŒ…æ‹¬ï¼š

- **è‡ªé€‚åº”ç¨€ç–ä½“ç´ å…‰æ …åŒ–**
- **å°„çº¿æ–¹å‘ç›¸å…³çš„è«é¡¿æ’åº**
- **å®æ—¶ä½“ç§¯æ¸²æŸ“**
- **å¤š GPU æ”¯æŒ**

**ä¸»è¦ç‰¹æ€§:**
- 16.7x æ¸²æŸ“åŠ é€Ÿ
- é«˜è¾¾ 65536Â³ ç½‘æ ¼åˆ†è¾¨ç‡
- å®æ—¶æ€§èƒ½ (>60 FPS)

**è¯¦ç»†æ–‡æ¡£:** [SVRaster CUDA æŒ‡å—](src/nerfs/svraster/README_cn.md#cuda-æ ¸å‡½æ•°ä½¿ç”¨æŒ‡å—)

### Plenoxels CUDA ä½¿ç”¨

Plenoxels ä¸“æ³¨äºä½“ç´ ç½‘æ ¼ä¼˜åŒ–ï¼ŒåŒ…æ‹¬ï¼š

- **é«˜æ•ˆä½“ç´ é‡‡æ ·**
- **CUDA ä¸‰çº¿æ€§æ’å€¼**
- **çƒè°å‡½æ•°è¯„ä¼°**
- **å†…å­˜ä¼˜åŒ–ç­–ç•¥**

**ä¸»è¦ç‰¹æ€§:**
- 16.6x æ¸²æŸ“åŠ é€Ÿ
- æ— ç¥ç»ç½‘ç»œæ¶æ„
- å¿«é€Ÿè®­ç»ƒæ”¶æ•›

**è¯¦ç»†æ–‡æ¡£:** [Plenoxels CUDA æŒ‡å—](src/nerfs/plenoxels/README_cn.md#cuda-æ ¸å‡½æ•°ä½¿ç”¨æŒ‡å—)

### InfNeRF CUDA ä½¿ç”¨

InfNeRF é’ˆå¯¹å¤§è§„æ¨¡åœºæ™¯ä¼˜åŒ–ï¼ŒåŒ…æ‹¬ï¼š

- **å…«å‰æ ‘éå†ä¼˜åŒ–**
- **å“ˆå¸Œç¼–ç åŠ é€Ÿ**
- **åˆ†å±‚å†…å­˜ç®¡ç†**
- **å†…å­˜é«˜æ•ˆæ¸²æŸ“**

**ä¸»è¦ç‰¹æ€§:**
- 16.8x æ¸²æŸ“åŠ é€Ÿ
- O(log n) ç©ºé—´å¤æ‚åº¦
- æ— é™å°ºåº¦åœºæ™¯æ”¯æŒ

**è¯¦ç»†æ–‡æ¡£:** [InfNeRF CUDA æŒ‡å—](src/nerfs/inf_nerf/README_cn.md#cuda-æ ¸å‡½æ•°ä½¿ç”¨æŒ‡å—)

## ğŸ› ï¸ é€šç”¨ CUDA å·¥å…·

### å†…å­˜ç®¡ç†

```python
from tools.cuda_utils import CUDAMemoryManager

# åˆ›å»ºå†…å­˜ç®¡ç†å™¨
memory_manager = CUDAMemoryManager(max_memory_gb=8.0)

# ç›‘æ§å†…å­˜ä½¿ç”¨
stats = memory_manager.get_memory_stats()
print(f"GPU å†…å­˜ä½¿ç”¨: {stats['utilization']:.1%}")
```

### æ€§èƒ½åˆ†æ

```python
from tools.cuda_utils import CUDAProfiler

# åˆ›å»ºæ€§èƒ½åˆ†æå™¨
profiler = CUDAProfiler()

# åˆ†ææ¸²æŸ“æ€§èƒ½
with profiler.profile("rendering"):
    result = model.render(rays_o, rays_d)

# è·å–ç»Ÿè®¡ä¿¡æ¯
stats = profiler.get_stats()
print(f"æ¸²æŸ“æ—¶é—´: {stats['avg_time']:.2f}ms")
```

### å¤š GPU æ”¯æŒ

```python
from tools.cuda_utils import MultiGPURenderer

# åˆ›å»ºå¤š GPU æ¸²æŸ“å™¨
renderer = MultiGPURenderer(
    model=model,
    num_gpus=torch.cuda.device_count(),
    strategy='ray_parallel'
)

# å¤š GPU æ¸²æŸ“
result = renderer.render_distributed(camera_poses, intrinsics)
```

## ğŸ”§ ä¼˜åŒ–å»ºè®®

### 1. ç¡¬ä»¶é…ç½®å»ºè®®

| GPU å‹å· | æ¨èé…ç½® | æ”¯æŒçš„æœ€å¤§åˆ†è¾¨ç‡ | é¢„æœŸæ€§èƒ½ |
|----------|----------|------------------|----------|
| RTX 4090 | 24GB VRAM | 1024Â³ ä½“ç´  | æœ€ä¼˜ |
| RTX 4080 | 16GB VRAM | 512Â³ ä½“ç´  | ä¼˜ç§€ |
| RTX 3080 | 12GB VRAM | 256Â³ ä½“ç´  | è‰¯å¥½ |
| RTX 3070 | 8GB VRAM | 128Â³ ä½“ç´  | åŸºæœ¬ |

### 2. å†…å­˜ä¼˜åŒ–

```python
# ä½¿ç”¨æ··åˆç²¾åº¦
model = model.half()

# å¯ç”¨ CUDA å†…å­˜ç¼“å­˜
torch.cuda.empty_cache()

# è®¾ç½®å†…å­˜åˆ†é…ç­–ç•¥
torch.cuda.set_per_process_memory_fraction(0.8)
```

### 3. æ€§èƒ½è°ƒä¼˜

```python
# å¯ç”¨ cuDNN ä¼˜åŒ–
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.deterministic = False

# ä½¿ç”¨ Tensor Core
torch.backends.cuda.matmul.allow_tf32 = True
```

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

### æ¸²æŸ“æ€§èƒ½å¯¹æ¯”

| åœºæ™¯ç±»å‹ | å›¾åƒåˆ†è¾¨ç‡ | SVRaster | Plenoxels | InfNeRF | ç»å…¸ NeRF |
|----------|------------|----------|-----------|---------|-----------|
| å®¤å†…åœºæ™¯ | 800x800 | 45ms | 52ms | 48ms | 750ms |
| æˆ·å¤–åœºæ™¯ | 1024x1024 | 78ms | 89ms | 85ms | 1200ms |
| å¤§è§„æ¨¡åœºæ™¯ | 1024x1024 | 95ms | N/A | 92ms | >5000ms |

### è®­ç»ƒæ€§èƒ½å¯¹æ¯”

| æ¨¡å‹ | è®­ç»ƒæ—¶é—´ | æ”¶æ•›è½®æ•° | å†…å­˜ä½¿ç”¨ | æœ€ç»ˆ PSNR |
|------|----------|----------|----------|-----------|
| SVRaster | 20min | 5K | 6GB | 32.5 dB |
| Plenoxels | 15min | 3K | 4GB | 31.8 dB |
| InfNeRF | 45min | 8K | 8GB | 33.2 dB |
| ç»å…¸ NeRF | 8h | 200K | 6GB | 31.5 dB |

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **CUDA å†…å­˜ä¸è¶³**
   ```bash
   # å‡å°‘æ‰¹æ¬¡å¤§å°
   export CUDA_BATCH_SIZE=4096
   
   # ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
   export CUDA_GRADIENT_CHECKPOINTING=1
   ```

2. **ç¼–è¯‘é”™è¯¯**
   ```bash
   # æ¸…ç†å¹¶é‡æ–°ç¼–è¯‘
   python tools/clean_cuda_cache.py
   python tools/build_cuda_extensions.py --force
   ```

3. **æ€§èƒ½ä¸ä½³**
   ```bash
   # æ£€æŸ¥ CUDA é©±åŠ¨
   nvidia-smi
   
   # æ›´æ–° PyTorch
   pip install torch --upgrade
   ```

### è°ƒè¯•å·¥å…·

```python
# CUDA è°ƒè¯•æ¨¡å¼
import os
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'

# å†…å­˜è°ƒè¯•
torch.cuda.memory._record_memory_history(True)
```

## ğŸ“š å‚è€ƒèµ„æ–™

### è®ºæ–‡é“¾æ¥

- [SVRaster: Sparse Voxels Rasterization](https://arxiv.org/abs/2024.xxxxx)
- [Plenoxels: Radiance Fields without Neural Networks](https://arxiv.org/abs/2112.05131)
- [InfNeRF: Towards Infinite Scale NeRF Rendering](https://arxiv.org/abs/2403.14376)

### ç›¸å…³å·¥å…·

- [CUDA Toolkit Documentation](https://docs.nvidia.com/cuda/)
- [PyTorch CUDA Documentation](https://pytorch.org/docs/stable/cuda.html)
- [cuDNN Documentation](https://docs.nvidia.com/deeplearning/cudnn/)

### ç¤¾åŒºèµ„æº

- [NeuroCity GitHub Issues](https://github.com/neurocity/neurocity/issues)
- [CUDA ä¼˜åŒ–æœ€ä½³å®è·µ](https://developer.nvidia.com/blog/cuda-pro-tip-write-flexible-kernels-grid-stride-loops/)
- [PyTorch æ€§èƒ½è°ƒä¼˜æŒ‡å—](https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html)

## ğŸ¤ è´¡çŒ®æŒ‡å—

å¦‚æœæ‚¨æƒ³ä¸º NeuroCity çš„ CUDA ä¼˜åŒ–åšå‡ºè´¡çŒ®ï¼š

1. **Fork é¡¹ç›®**
2. **åˆ›å»º CUDA åˆ†æ”¯**
3. **ç¼–å†™æµ‹è¯•**
4. **æäº¤ PR**

è¯¦ç»†çš„è´¡çŒ®æŒ‡å—è¯·å‚è€ƒ [CONTRIBUTING.md](CONTRIBUTING.md)ã€‚

## ğŸ“ æ”¯æŒ

å¦‚æœæ‚¨é‡åˆ° CUDA ç›¸å…³é—®é¢˜ï¼Œè¯·ï¼š

1. æŸ¥çœ‹ç›¸å…³æ¨¡å—çš„ CUDA æ–‡æ¡£
2. æ£€æŸ¥ [FAQ](FAQ.md) ä¸­çš„å¸¸è§é—®é¢˜
3. åœ¨ [GitHub Issues](https://github.com/neurocity/neurocity/issues) ä¸­æé—®
4. å‚ä¸ç¤¾åŒºè®¨è®º

---

*æœ€åæ›´æ–°: 2024å¹´12æœˆ*
