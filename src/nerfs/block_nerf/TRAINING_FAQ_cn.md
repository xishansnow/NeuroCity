# Block-NeRF è®­ç»ƒå¸¸è§é—®é¢˜è§£ç­” (FAQ)

**ç‰ˆæœ¬**: 1.0  
**æ—¥æœŸ**: 2025å¹´7æœˆ5æ—¥  
**è¯´æ˜**: Block-NeRF è®­ç»ƒè¿‡ç¨‹ä¸­çš„å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

---

## ğŸ“‹ ç›®å½•

- [ç¯å¢ƒé…ç½®é—®é¢˜](#ç¯å¢ƒé…ç½®é—®é¢˜)
- [æ•°æ®å‡†å¤‡é—®é¢˜](#æ•°æ®å‡†å¤‡é—®é¢˜)
- [è®­ç»ƒè¿‡ç¨‹é—®é¢˜](#è®­ç»ƒè¿‡ç¨‹é—®é¢˜)
- [æ€§èƒ½ä¼˜åŒ–é—®é¢˜](#æ€§èƒ½ä¼˜åŒ–é—®é¢˜)
- [æ¸²æŸ“è´¨é‡é—®é¢˜](#æ¸²æŸ“è´¨é‡é—®é¢˜)
- [è°ƒè¯•å’Œé”™è¯¯å¤„ç†](#è°ƒè¯•å’Œé”™è¯¯å¤„ç†)
- [ç¡¬ä»¶ç›¸å…³é—®é¢˜](#ç¡¬ä»¶ç›¸å…³é—®é¢˜)
- [é«˜çº§åº”ç”¨é—®é¢˜](#é«˜çº§åº”ç”¨é—®é¢˜)

---

## ğŸ”§ ç¯å¢ƒé…ç½®é—®é¢˜

### Q1: å®‰è£…ä¾èµ–æ—¶é‡åˆ° CUDA ç‰ˆæœ¬ä¸åŒ¹é…æ€ä¹ˆåŠï¼Ÿ

**A**: ç¡®ä¿ PyTorch ç‰ˆæœ¬ä¸ CUDA ç‰ˆæœ¬åŒ¹é…ï¼š

```bash
# æŸ¥çœ‹å½“å‰ CUDA ç‰ˆæœ¬
nvidia-smi

# å®‰è£…å¯¹åº”ç‰ˆæœ¬çš„ PyTorch
# CUDA 11.8
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
```

### Q2: ç¼–è¯‘ CUDA æ‰©å±•æ—¶å‡ºé”™ï¼Ÿ

**A**: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. ç¡®ä¿å®‰è£…äº†æ­£ç¡®çš„ CUDA toolkit
2. æ£€æŸ¥ GCC ç‰ˆæœ¬å…¼å®¹æ€§ï¼ˆæ¨è GCC 7-9ï¼‰
3. è®¾ç½®ç¯å¢ƒå˜é‡ï¼š

```bash
export CUDA_HOME=/usr/local/cuda
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
```

### Q3: å†…å­˜ä¸è¶³é”™è¯¯å¦‚ä½•è§£å†³ï¼Ÿ

**A**: å¤šç§è§£å†³æ–¹æ¡ˆï¼š
- å‡å°‘ batch size
- ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
- å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
- è°ƒæ•´å—å¤§å°å‚æ•°

```python
# é…ç½®ç¤ºä¾‹
config = {
    'batch_size': 2048,  # å‡å°‘åˆ° 1024 æˆ– 512
    'gradient_accumulation_steps': 4,
    'mixed_precision': True,
    'block_size': [64, 64, 64],  # å‡å°‘å—å¤§å°
}
```

---

## ğŸ“Š æ•°æ®å‡†å¤‡é—®é¢˜

### Q4: SfM é‡å»ºå¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A**: å¸¸è§åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š

1. **å›¾åƒè´¨é‡é—®é¢˜**ï¼š
   - ç¡®ä¿å›¾åƒæ¸…æ™°ï¼Œé¿å…æ¨¡ç³Š
   - æ£€æŸ¥æ›å…‰æ˜¯å¦è¿‡åº¦æˆ–ä¸è¶³
   - ç§»é™¤é‡å¤æˆ–ç›¸ä¼¼åº¦è¿‡é«˜çš„å›¾åƒ

2. **ç›¸æœºè¿åŠ¨é—®é¢˜**ï¼š
   - ç¡®ä¿ç›¸æœºè¿åŠ¨è½¨è¿¹åˆç†
   - é¿å…å¿«é€Ÿè¿åŠ¨æˆ–å‰§çƒˆæŠ–åŠ¨
   - å¢åŠ å…³é”®å¸§å¯†åº¦

3. **COLMAP å‚æ•°è°ƒä¼˜**ï¼š
   ```bash
   # ä½¿ç”¨æ›´å®½æ¾çš„åŒ¹é…å‚æ•°
   colmap feature_extractor --ImageReader.camera_model PINHOLE --SiftExtraction.max_image_size 1600
   colmap exhaustive_matcher --SiftMatching.max_ratio 0.8 --SiftMatching.max_distance 0.9
   ```

### Q5: åœºæ™¯åˆ†è§£å‚æ•°å¦‚ä½•é€‰æ‹©ï¼Ÿ

**A**: æ ¹æ®åœºæ™¯ç‰¹ç‚¹è°ƒæ•´ï¼š

```python
# åŸå¸‚åœºæ™¯
block_config = {
    'block_size': [100, 100, 50],  # ç±³ä¸ºå•ä½
    'overlap_ratio': 0.2,
    'min_images_per_block': 20,
    'max_images_per_block': 200,
}

# å®¤å†…åœºæ™¯
block_config = {
    'block_size': [10, 10, 5],
    'overlap_ratio': 0.3,
    'min_images_per_block': 10,
    'max_images_per_block': 100,
}
```

### Q6: æ•°æ®é›†æ ¼å¼è½¬æ¢é—®é¢˜ï¼Ÿ

**A**: ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®ï¼š

```python
# æ ‡å‡†æ•°æ®ç»“æ„
dataset_root/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ image_001.jpg
â”‚   â”œâ”€â”€ image_002.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ poses.json          # ç›¸æœºå§¿æ€
â”œâ”€â”€ intrinsics.json     # å†…å‚
â””â”€â”€ blocks.json         # å—åˆ†è§£ä¿¡æ¯
```

---

## ğŸ¯ è®­ç»ƒè¿‡ç¨‹é—®é¢˜

### Q7: æŸå¤±ä¸æ”¶æ•›æ€ä¹ˆåŠï¼Ÿ

**A**: åˆ†æ­¥è¯Šæ–­ï¼š

1. **æ£€æŸ¥å­¦ä¹ ç‡**ï¼š
   ```python
   # é™ä½å­¦ä¹ ç‡
   lr_config = {
       'nerf_lr': 1e-4,      # ä» 5e-4 é™åˆ° 1e-4
       'pose_lr': 1e-5,      # ä» 1e-4 é™åˆ° 1e-5
       'appearance_lr': 1e-3,
   }
   ```

2. **æ£€æŸ¥æ•°æ®è´¨é‡**ï¼š
   - éªŒè¯ç›¸æœºå§¿æ€å‡†ç¡®æ€§
   - æ£€æŸ¥å›¾åƒæ ‡æ³¨è´¨é‡
   - ç¡®è®¤å—åˆ†è§£åˆç†æ€§

3. **è°ƒæ•´æŸå¤±æƒé‡**ï¼š
   ```python
   loss_weights = {
       'rgb_loss': 1.0,
       'depth_loss': 0.1,    # é™ä½æ·±åº¦æŸå¤±æƒé‡
       'appearance_reg': 0.01,
       'pose_reg': 0.001,
   }
   ```

### Q8: è®­ç»ƒé€Ÿåº¦å¤ªæ…¢æ€ä¹ˆä¼˜åŒ–ï¼Ÿ

**A**: å¤šé‡ä¼˜åŒ–ç­–ç•¥ï¼š

1. **æ•°æ®åŠ è½½ä¼˜åŒ–**ï¼š
   ```python
   dataloader_config = {
       'num_workers': 8,
       'pin_memory': True,
       'prefetch_factor': 4,
   }
   ```

2. **æ¨¡å‹ä¼˜åŒ–**ï¼š
   - ä½¿ç”¨æ›´å°çš„ç½‘ç»œ
   - å‡å°‘é‡‡æ ·ç‚¹æ•°é‡
   - å¯ç”¨æ‰¹å¤„ç†æ¨ç†

3. **ç¡¬ä»¶ä¼˜åŒ–**ï¼š
   - ä½¿ç”¨å¤šGPUè®­ç»ƒ
   - å¯ç”¨æ··åˆç²¾åº¦
   - ä½¿ç”¨ NVMe SSD å­˜å‚¨æ•°æ®

### Q9: å‡ºç° NaN å€¼æ€ä¹ˆå¤„ç†ï¼Ÿ

**A**: ç³»ç»Ÿæ€§æ’æŸ¥ï¼š

1. **æ¢¯åº¦è£å‰ª**ï¼š
   ```python
   torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
   ```

2. **æ•°å€¼ç¨³å®šæ€§**ï¼š
   ```python
   # åœ¨ softmax å’Œ log æ“ä½œä¸­æ·»åŠ  eps
   weights = F.softmax(raw_weights + 1e-8, dim=-1)
   density = F.relu(raw_density) + 1e-8
   ```

3. **å­¦ä¹ ç‡è°ƒæ•´**ï¼š
   - é™ä½åˆå§‹å­¦ä¹ ç‡
   - ä½¿ç”¨ warmup ç­–ç•¥
   - ç›‘æ§æ¢¯åº¦èŒƒæ•°

---

## ğŸš€ æ€§èƒ½ä¼˜åŒ–é—®é¢˜

### Q10: å¦‚ä½•æé«˜è®­ç»ƒæ•ˆç‡ï¼Ÿ

**A**: ç»¼åˆä¼˜åŒ–æ–¹æ¡ˆï¼š

1. **æ¨¡å‹å‰ªæ**ï¼š
   ```python
   # åŠ¨æ€ç½‘ç»œå¤§å°
   config = {
       'coarse_samples': 64,    # å‡å°‘ç²—é‡‡æ ·ç‚¹
       'fine_samples': 128,     # å‡å°‘ç²¾é‡‡æ ·ç‚¹
       'network_depth': 6,      # å‡å°‘ç½‘ç»œæ·±åº¦
       'network_width': 128,    # å‡å°‘ç½‘ç»œå®½åº¦
   }
   ```

2. **é‡‡æ ·ä¼˜åŒ–**ï¼š
   ```python
   # é‡è¦æ€§é‡‡æ ·
   sampling_config = {
       'hierarchical_sampling': True,
       'use_importance_sampling': True,
       'adaptive_sampling': True,
   }
   ```

3. **ç¼“å­˜ç­–ç•¥**ï¼š
   ```python
   # ç‰¹å¾ç¼“å­˜
   cache_config = {
       'cache_embeddings': True,
       'cache_size': 10000,
       'cache_rays': True,
   }
   ```

### Q11: å¤šGPUè®­ç»ƒè®¾ç½®ï¼Ÿ

**A**: åˆ†å¸ƒå¼è®­ç»ƒé…ç½®ï¼š

```python
# å¯åŠ¨è„šæœ¬
python -m torch.distributed.launch \
    --nproc_per_node=4 \
    --master_port=12345 \
    train_block_nerf.py \
    --config configs/multi_gpu.yaml

# ä»£ç é…ç½®
def setup_distributed():
    torch.distributed.init_process_group(backend='nccl')
    local_rank = torch.distributed.get_rank()
    torch.cuda.set_device(local_rank)
    
# æ¨¡å‹åŒ…è£…
model = torch.nn.parallel.DistributedDataParallel(
    model, device_ids=[local_rank]
)
```

---

## ğŸ¨ æ¸²æŸ“è´¨é‡é—®é¢˜

### Q12: æ¸²æŸ“ç»“æœæœ‰ä¼ªå½±æ€ä¹ˆè§£å†³ï¼Ÿ

**A**: é’ˆå¯¹ä¸åŒä¼ªå½±ç±»å‹ï¼š

1. **å—è¾¹ç•Œä¼ªå½±**ï¼š
   ```python
   # å¢åŠ é‡å åŒºåŸŸ
   block_config['overlap_ratio'] = 0.3  # ä» 0.2 å¢åŠ åˆ° 0.3
   
   # æ”¹è¿›æ··åˆç­–ç•¥
   blending_config = {
       'blend_method': 'gaussian',
       'blend_sigma': 2.0,
       'smooth_boundary': True,
   }
   ```

2. **å¤–è§‚ä¸ä¸€è‡´**ï¼š
   ```python
   # å¢å¼ºå¤–è§‚åµŒå…¥
   appearance_config = {
       'embedding_dim': 48,     # å¢åŠ åµŒå…¥ç»´åº¦
       'use_global_appearance': True,
       'appearance_smooth_loss': 0.01,
   }
   ```

3. **æ·±åº¦ä¸è¿ç»­**ï¼š
   ```python
   # æ·±åº¦å¹³æ»‘æŸå¤±
   depth_config = {
       'depth_smooth_loss': 0.1,
       'depth_consistency_loss': 0.05,
   }
   ```

### Q13: å¦‚ä½•æé«˜æ¸²æŸ“ç»†èŠ‚ï¼Ÿ

**A**: å¤šå±‚æ¬¡ä¼˜åŒ–ï¼š

1. **å¢åŠ é‡‡æ ·å¯†åº¦**ï¼š
   ```python
   sampling_config = {
       'coarse_samples': 128,   # å¢åŠ é‡‡æ ·ç‚¹
       'fine_samples': 256,
       'max_depth_samples': 512,
   }
   ```

2. **ä½¿ç”¨ä½ç½®ç¼–ç **ï¼š
   ```python
   encoding_config = {
       'positional_encoding_levels': 12,  # å¢åŠ ç¼–ç å±‚æ¬¡
       'directional_encoding_levels': 6,
   }
   ```

### Q14: è¿œè·ç¦»æ¸²æŸ“è´¨é‡å·®ï¼Ÿ

**A**: è·ç¦»ç›¸å…³ä¼˜åŒ–ï¼š

```python
# è·ç¦»è‡ªé€‚åº”é‡‡æ ·
distance_config = {
    'near_samples': 256,      # è¿‘è·ç¦»é«˜é‡‡æ ·
    'far_samples': 64,        # è¿œè·ç¦»ä½é‡‡æ ·
    'distance_threshold': 50.0,
    'adaptive_sampling': True,
}

# è·ç¦»ç›¸å…³æŸå¤±æƒé‡
def distance_weighted_loss(pred, gt, distances):
    weights = 1.0 / (1.0 + distances / 100.0)
    return torch.mean(weights * F.mse_loss(pred, gt, reduction='none'))
```

---

## ğŸ› è°ƒè¯•å’Œé”™è¯¯å¤„ç†

### Q15: å¦‚ä½•è°ƒè¯•è®­ç»ƒè¿‡ç¨‹ï¼Ÿ

**A**: ç³»ç»Ÿæ€§è°ƒè¯•æ–¹æ³•ï¼š

1. **å¯è§†åŒ–è°ƒè¯•**ï¼š
   ```python
   # å®šæœŸä¿å­˜ä¸­é—´ç»“æœ
   if step % 1000 == 0:
       save_debug_images(model, val_data, step)
       save_loss_curves(losses, step)
       save_model_weights(model, step)
   ```

2. **æ—¥å¿—åˆ†æ**ï¼š
   ```python
   # è¯¦ç»†æ—¥å¿—è®°å½•
   logging.basicConfig(level=logging.DEBUG)
   logger.info(f"Iteration {step}: RGB Loss = {rgb_loss:.6f}")
   logger.debug(f"Gradient norms: {grad_norms}")
   ```

3. **æ£€æŸ¥ç‚¹æ¢å¤**ï¼š
   ```python
   # ä¿å­˜è®­ç»ƒçŠ¶æ€
   torch.save({
       'model_state_dict': model.state_dict(),
       'optimizer_state_dict': optimizer.state_dict(),
       'step': step,
       'loss': loss,
   }, f'checkpoint_{step}.pth')
   ```

### Q16: å¸¸è§é”™è¯¯ç å’Œè§£å†³æ–¹æ¡ˆï¼Ÿ

**A**: é”™è¯¯ç å‚è€ƒè¡¨ï¼š

| é”™è¯¯ç±»å‹ | å¸¸è§åŸå›  | è§£å†³æ–¹æ¡ˆ |
|---------|---------|---------|
| CUDA OOM | å†…å­˜ä¸è¶³ | å‡å°‘batch sizeï¼Œå¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ |
| RuntimeError | å¼ é‡å½¢çŠ¶ä¸åŒ¹é… | æ£€æŸ¥æ•°æ®ç»´åº¦ï¼ŒéªŒè¯æ¨¡å‹è¾“å…¥ |
| KeyError | é…ç½®é¡¹ç¼ºå¤± | æ£€æŸ¥é…ç½®æ–‡ä»¶å®Œæ•´æ€§ |
| FileNotFoundError | æ•°æ®è·¯å¾„é”™è¯¯ | éªŒè¯æ•°æ®è·¯å¾„ï¼Œæ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§ |
| ValueError | å‚æ•°å€¼é”™è¯¯ | æ£€æŸ¥å‚æ•°èŒƒå›´å’Œç±»å‹ |

---

## ğŸ’» ç¡¬ä»¶ç›¸å…³é—®é¢˜

### Q17: æœ€ä½ç¡¬ä»¶è¦æ±‚ï¼Ÿ

**A**: æ¨èé…ç½®ï¼š

```
æœ€ä½é…ç½®ï¼š
- GPU: GTX 1080 (8GB)
- CPU: Intel i5-8400 / AMD R5 3600
- RAM: 16GB
- å­˜å‚¨: 500GB SSD

æ¨èé…ç½®ï¼š
- GPU: RTX 3080/4080 (12GB+)
- CPU: Intel i7-10700K / AMD R7 5800X
- RAM: 32GB
- å­˜å‚¨: 1TB NVMe SSD

é«˜ç«¯é…ç½®ï¼š
- GPU: RTX 4090 (24GB) æˆ–å¤šå¡
- CPU: Intel i9-12900K / AMD R9 5950X
- RAM: 64GB+
- å­˜å‚¨: 2TB+ NVMe SSD
```

### Q18: å¦‚ä½•ä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼Ÿ

**A**: å†…å­˜ä¼˜åŒ–ç­–ç•¥ï¼š

```python
# æ¢¯åº¦æ£€æŸ¥ç‚¹
model.enable_gradient_checkpointing()

# æ•°æ®ç±»å‹ä¼˜åŒ–
model.half()  # ä½¿ç”¨ FP16

# æ‰¹å¤„ç†ä¼˜åŒ–
def chunk_processing(data, chunk_size=1024):
    results = []
    for i in range(0, len(data), chunk_size):
        chunk = data[i:i+chunk_size]
        with torch.cuda.amp.autocast():
            result = model(chunk)
        results.append(result.cpu())
    return torch.cat(results)
```

---

## ğŸ“ é«˜çº§åº”ç”¨é—®é¢˜

### Q19: å¦‚ä½•é›†æˆåˆ°ç”Ÿäº§ç¯å¢ƒï¼Ÿ

**A**: ç”Ÿäº§éƒ¨ç½²ç­–ç•¥ï¼š

1. **æ¨¡å‹ä¼˜åŒ–**ï¼š
   ```python
   # æ¨¡å‹å‹ç¼©
   torch.jit.script(model)  # TorchScript
   
   # é‡åŒ–
   torch.quantization.quantize_dynamic(model)
   
   # ONNX å¯¼å‡º
   torch.onnx.export(model, dummy_input, "model.onnx")
   ```

2. **æœåŠ¡åŒ–éƒ¨ç½²**ï¼š
   ```python
   # Flask API ç¤ºä¾‹
   @app.route('/render', methods=['POST'])
   def render_view():
       camera_pose = request.json['camera_pose']
       image = model.render(camera_pose)
       return jsonify({'image': image.tolist()})
   ```

### Q20: å¦‚ä½•å¤„ç†åŠ¨æ€åœºæ™¯ï¼Ÿ

**A**: åŠ¨æ€åœºæ™¯æ‰©å±•ï¼š

```python
# æ—¶åºå»ºæ¨¡
class TemporalBlockNeRF(BlockNeRF):
    def __init__(self, config):
        super().__init__(config)
        self.time_encoding = TimeEncoding(config.time_dim)
    
    def forward(self, rays, time_stamps):
        # æ—¶é—´ç¼–ç 
        time_features = self.time_encoding(time_stamps)
        # ç»“åˆç©ºé—´å’Œæ—¶é—´ç‰¹å¾
        return self.render_with_time(rays, time_features)
```

---

## ğŸ“ˆ æ€§èƒ½åŸºå‡†å’ŒæœŸæœ›

### Q21: æ­£å¸¸çš„è®­ç»ƒæŒ‡æ ‡èŒƒå›´ï¼Ÿ

**A**: å‚è€ƒåŸºå‡†ï¼š

```
è®­ç»ƒæŒ‡æ ‡å‚è€ƒå€¼ï¼š
- RGB Loss: 0.01 - 0.05 (æ”¶æ•›å)
- PSNR: 25-35 dB (éªŒè¯é›†)
- SSIM: 0.8-0.95
- LPIPS: 0.1-0.3
- è®­ç»ƒæ—¶é—´: 2-7å¤© (åŸå¸‚åœºæ™¯)

æ”¶æ•›åˆ¤æ–­æ ‡å‡†ï¼š
- æŸå¤±è¿ç»­100ä¸ªepochå˜åŒ– < 1%
- éªŒè¯é›†PSNRæå‡ < 0.1 dB
- æ¸²æŸ“è´¨é‡ä¸»è§‚è¯„ä¼°æ»¡æ„
```

### Q22: å¦‚ä½•è¯„ä¼°æ¨¡å‹è´¨é‡ï¼Ÿ

**A**: å¤šç»´åº¦è¯„ä¼°ï¼š

```python
def evaluate_model(model, test_data):
    metrics = {}
    
    # å›¾åƒè´¨é‡æŒ‡æ ‡
    psnr_scores = []
    ssim_scores = []
    lpips_scores = []
    
    for data in test_data:
        pred_img = model.render(data['camera'])
        gt_img = data['image']
        
        psnr_scores.append(compute_psnr(pred_img, gt_img))
        ssim_scores.append(compute_ssim(pred_img, gt_img))
        lpips_scores.append(compute_lpips(pred_img, gt_img))
    
    metrics.update({
        'PSNR': np.mean(psnr_scores),
        'SSIM': np.mean(ssim_scores),
        'LPIPS': np.mean(lpips_scores),
    })
    
    return metrics
```

---

## ğŸ†˜ è·å–å¸®åŠ©

å¦‚æœä»¥ä¸ŠFAQæ²¡æœ‰è§£å†³æ‚¨çš„é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–å¸®åŠ©ï¼š

1. **æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£**ï¼šå‚è€ƒ [TRAINING_DOCUMENTATION_INDEX_cn.md](./TRAINING_DOCUMENTATION_INDEX_cn.md)
2. **GitHub Issues**ï¼šåœ¨é¡¹ç›®ä»“åº“åˆ›å»º Issue
3. **ç¤¾åŒºè®¨è®º**ï¼šå‚ä¸ç›¸å…³æŠ€æœ¯è®ºå›å’Œç¤¾åŒº
4. **è®ºæ–‡åŸæ–‡**ï¼šä»”ç»†é˜…è¯» Block-NeRF åŸè®ºæ–‡

---

**æœ€åæ›´æ–°**: 2025å¹´7æœˆ5æ—¥  
**ç»´æŠ¤è€…**: NeuroCity å¼€å‘å›¢é˜Ÿ

*æŒç»­æ›´æ–°ä¸­ï¼Œæ¬¢è¿è´¡çŒ®æ›´å¤šé—®é¢˜å’Œè§£å†³æ–¹æ¡ˆï¼* ğŸš€
