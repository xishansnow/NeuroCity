# SVRaster API å‚è€ƒæ–‡æ¡£

æœ¬æ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆï¼ŒåŒ…å« SVRaster æ¨¡å—çš„æ‰€æœ‰å…¬å…± APIã€‚

## ğŸ“š ç›®å½•

### ğŸ—ï¸ ç±» (Classes)

- [AdaptiveSparseVoxels](#adaptivesparsevoxels)
- [EMAModel](#emamodel)
- [InteractiveRenderer](#interactiverenderer)
- [SVRasterConfig](#svrasterconfig)
- [SVRasterDataset](#svrasterdataset)
- [SVRasterDatasetConfig](#svrasterdatasetconfig)
- [SVRasterGPU](#svrastergpu)
- [SVRasterGPUTrainer](#svrastergputrainer)
- [SVRasterLoss](#svrasterloss)
- [SVRasterModel](#svrastermodel)
- [SVRasterOptimizedKernels](#svrasteroptimizedkernels)
- [SVRasterRenderer](#svrasterrenderer)
- [SVRasterRendererConfig](#svrasterrendererconfig)
- [SVRasterTrainer](#svrastertrainer)
- [SVRasterTrainerConfig](#svrastertrainerconfig)
- [VoxelRasterizer](#voxelrasterizer)

### ğŸ”§ å‡½æ•° (Functions)

- [compact1by2](#compact1by2)
- [compute_morton_order](#compute_morton_order)
- [compute_octree_level](#compute_octree_level)
- [compute_ray_aabb_intersection](#compute_ray_aabb_intersection)
- [compute_ray_samples](#compute_ray_samples)
- [compute_ssim](#compute_ssim)
- [compute_voxel_bounds](#compute_voxel_bounds)
- [create_svraster_dataloader](#create_svraster_dataloader)
- [create_svraster_dataset](#create_svraster_dataset)
- [create_svraster_trainer](#create_svraster_trainer)
- [depth_peeling](#depth_peeling)
- [eval_sh_basis](#eval_sh_basis)
- [get_compute_capability](#get_compute_capability)
- [get_cuda_version](#get_cuda_version)
- [get_octree_neighbors](#get_octree_neighbors)
- [main](#main)
- [morton_decode_3d](#morton_decode_3d)
- [morton_decode_batch](#morton_decode_batch)
- [morton_encode_3d](#morton_encode_3d)
- [morton_encode_batch](#morton_encode_batch)
- [octree_pruning](#octree_pruning)
- [octree_subdivision](#octree_subdivision)
- [part1by2](#part1by2)
- [part1by2](#part1by2)
- [part1by2_vectorized](#part1by2_vectorized)
- [part1by2_vectorized](#part1by2_vectorized)
- [ray_direction_dependent_ordering](#ray_direction_dependent_ordering)
- [render_rays](#render_rays)
- [sort_by_morton_order](#sort_by_morton_order)
- [volume_rendering_integration](#volume_rendering_integration)
- [voxel_pruning](#voxel_pruning)
- [voxel_to_world_coords](#voxel_to_world_coords)
- [world_to_voxel_coords](#world_to_voxel_coords)

## ğŸ—ï¸ ç±» (Classes)

### AdaptiveSparseVoxels

è‡ªé€‚åº”ç¨€ç–ä½“ç´ è¡¨ç¤ºç±»

è¿™ä¸ªç±»å®ç°äº†åŸºäºå…«å‰æ ‘çš„å¤šåˆ†è¾¨ç‡è‡ªé€‚åº”ç¨€ç–ä½“ç´ è¡¨ç¤ºï¼Œæ˜¯ SVRaster çš„æ ¸å¿ƒç»„ä»¶ã€‚
å®ƒç®¡ç†ä¸åŒå…«å‰æ ‘å±‚çº§çš„ç¨€ç–ä½“ç´ ï¼Œåªå­˜å‚¨å¶å­èŠ‚ç‚¹ï¼Œä¸å­˜å‚¨å®Œæ•´çš„å…«å‰æ ‘ç»“æ„ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. åˆå§‹åŒ–åŸºç¡€ä½“ç´ ç½‘æ ¼
2. æ ¹æ®æ¢¯åº¦æˆ–å¯†åº¦è¿›è¡Œè‡ªé€‚åº”ç»†åˆ†
3. åŸºäºå¯†åº¦é˜ˆå€¼è¿›è¡Œä½“ç´ å‰ªæ
4. è®¡ç®— Morton ç ç”¨äºæ·±åº¦æ’åº
5. ç®¡ç†å¤šå±‚çº§ä½“ç´ çš„å‚é‡å€¼

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/core.py`

#### æ–¹æ³• (Methods)

##### `__init__(self, config: SVRasterConfig)`

*æš‚æ— æ–‡æ¡£*

---

##### `add_voxels(self, positions, sizes, densities, colors, level = 0)`

å‘æŒ‡å®šå±‚çº§æ·»åŠ ä½“ç´ ã€‚
Args:
    positions: [N, 3] ä½“ç´ ä¸­å¿ƒ
    sizes: [N] ä½“ç´ å°ºå¯¸
    densities: [N] ä½“ç´ å¯†åº¦
    colors: [N, 3 * (sh_degree+1)^2] ä½“ç´ é¢œè‰²/SHç³»æ•°
    level: int, å±‚çº§ç´¢å¼•

---

##### `get_all_voxels(self) -> dict[str, torch.Tensor]`

è·å–æ‰€æœ‰å±‚çº§çš„ä½“ç´ æ•°æ®

å°†æ‰€æœ‰å±‚çº§çš„ä½“ç´ æ•°æ®åˆå¹¶ä¸ºä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«ä½ç½®ã€å¤§å°ã€å¯†åº¦ã€
é¢œè‰²ã€å±‚çº§å’Œ Morton ç ã€‚

Returns:
    åŒ…å«æ‰€æœ‰ä½“ç´ æ•°æ®çš„å­—å…¸

---

##### `get_total_voxel_count(self) -> int`

è·å–æ‰€æœ‰å±‚çº§çš„ä½“ç´ æ€»æ•°

Returns:
    ä½“ç´ æ€»æ•°

---

##### `parameters(self) -> list[torch.Tensor]`

Get all optimizable parameters.

---

##### `prune_voxels(self, threshold: Optional[float] = None)`

ç§»é™¤ä½å¯†åº¦ä½“ç´ 

æ ¹æ®å¯†åº¦é˜ˆå€¼ç§»é™¤ä¸é‡è¦çš„ä½“ç´ ï¼Œå‡å°‘å†…å­˜ä½¿ç”¨å¹¶æé«˜æ¸²æŸ“æ•ˆç‡ã€‚
å¯†åº¦ä½äºé˜ˆå€¼çš„ä½“ç´ è¢«è®¤ä¸ºæ˜¯é€æ˜çš„ï¼Œå¯¹æœ€ç»ˆæ¸²æŸ“ç»“æœè´¡çŒ®å¾ˆå°ã€‚

Args:
    threshold: å¯†åº¦é˜ˆå€¼ï¼ŒNone æ—¶ä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤å€¼

---

##### `subdivide_voxels(self, subdivision_mask: torch.Tensor, level_idx: int)`

æ ¹æ®ç»†åˆ†æ©ç ç»†åˆ†ä½“ç´ 

å°†é€‰ä¸­çš„ä½“ç´ ç»†åˆ†ä¸º 8 ä¸ªå­ä½“ç´ ï¼Œæ¯ä¸ªå­ä½“ç´ çš„å¤§å°æ˜¯çˆ¶ä½“ç´ çš„ä¸€åŠã€‚
ç»†åˆ†åçš„å­ä½“ç´ è¢«æ·»åŠ åˆ°ä¸‹ä¸€å±‚çº§ï¼Œçˆ¶ä½“ç´ è¢«ç§»é™¤ã€‚

Args:
    subdivision_mask: ç»†åˆ†æ©ç ï¼ŒTrue è¡¨ç¤ºéœ€è¦ç»†åˆ†çš„ä½“ç´ 
    level_idx: å½“å‰å±‚çº§ç´¢å¼•

---



### EMAModel

Exponential Moving Average model wrapper.

Maintains moving averages of model parameters during training.
This can help produce more stable and better performing models.

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/cuda/ema.py`

#### æ–¹æ³• (Methods)

##### `__init__(self, model: torch.nn.Module, decay: float = 0.999, device: Optional[torch.device] = None)`

Initialize EMA model.

Args:
    model: The model whose parameters we want to maintain averages for
    decay: The decay rate for the moving average (default: 0.999)
    device: The device to store the EMA parameters on

---

##### `apply_shadow(self, model: torch.nn.Module) -> None`

Apply the moving averages to the model parameters.

Args:
    model: The model whose parameters to update with the moving averages

---

##### `load_state_dict(self, state_dict: Dict[str, torch.Tensor]) -> None`

Load a state dictionary into the EMA model.

Args:
    state_dict: The state dictionary to load

---

##### `restore_original(self, model: torch.nn.Module) -> None`

Restore the original model parameters.

Args:
    model: The model whose parameters to restore

---

##### `state_dict(self) -> Dict[str, torch.Tensor]`

Get the state dictionary of the EMA model.

---

##### `update(self, model: torch.nn.Module) -> None`

Update moving averages of model parameters.

Args:
    model: The model whose parameters to update the moving averages with

---



### InteractiveRenderer

äº¤äº’å¼æ¸²æŸ“å™¨

æä¾›å®æ—¶ç›¸æœºæ§åˆ¶å’Œæ¸²æŸ“åŠŸèƒ½

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/renderer.py`

#### æ–¹æ³• (Methods)

##### `__init__(self, renderer: SVRasterRenderer, initial_pose: torch.Tensor, intrinsics: torch.Tensor, image_size: Optional[Tuple[int, int]] = None)`

*æš‚æ— æ–‡æ¡£*

---

##### `move_camera(self, direction: str, distance: Optional[float] = None) -> torch.Tensor`

ç§»åŠ¨ç›¸æœº

Args:
    direction: ç§»åŠ¨æ–¹å‘ ("forward", "backward", "left", "right", "up", "down")
    distance: ç§»åŠ¨è·ç¦»ï¼ŒNone æ—¶ä½¿ç”¨é»˜è®¤é€Ÿåº¦

Returns:
    æ¸²æŸ“ç»“æœ

---

##### `render_current_view(self) -> torch.Tensor`

æ¸²æŸ“å½“å‰è§†è§’

Returns:
    æ¸²æŸ“çš„RGBå›¾åƒ

---

##### `rotate_camera(self, yaw: float = 0, pitch: float = 0) -> torch.Tensor`

æ—‹è½¬ç›¸æœº

Args:
    yaw: åèˆªè§’ï¼ˆå¼§åº¦ï¼‰
    pitch: ä¿¯ä»°è§’ï¼ˆå¼§åº¦ï¼‰

Returns:
    æ¸²æŸ“ç»“æœ

---

##### `set_pose(self, pose: torch.Tensor) -> torch.Tensor`

è®¾ç½®ç›¸æœºä½å§¿

Args:
    pose: æ–°çš„ç›¸æœºä½å§¿

Returns:
    æ¸²æŸ“ç»“æœ

---



### SVRasterConfig

SVRaster configuration.

Attributes:
    # Scene representation
    max_octree_levels: Maximum octree levels
    base_resolution: Base grid resolution
    scene_bounds: Scene bounds (min_x, min_y, min_z, max_x, max_y, max_z)

    # Voxel properties
    density_activation: Density activation function
    color_activation: Color activation function
    sh_degree: Spherical harmonics degree

    # Training
    learning_rate: Learning rate
    weight_decay: Weight decay
    gradient_clip_val: Gradient clipping value
    use_ema: Whether to use EMA model
    ema_decay: EMA decay rate
    steps_per_epoch: Number of steps per epoch
    num_epochs: Number of epochs
    save_best: Whether to save best model

    # Dataset
    image_width: Image width
    image_height: Image height
    camera_angle_x: Camera horizontal FoV in radians
    data_dir: Data directory
    num_rays_train: Number of rays per training batch
    downscale_factor: Image downscale factor for training

    # Rendering
    ray_samples_per_voxel: Number of samples per voxel along ray
    depth_peeling_layers: Number of depth peeling layers
    morton_ordering: Whether to use Morton ordering for depth sorting
    background_color: Background color (RGB)
    near_plane: Near plane distance
    far_plane: Far plane distance
    use_view_dependent_color: Whether to use view-dependent color
    use_opacity_regularization: Whether to use opacity regularization
    opacity_reg_weight: Opacity regularization weight
    use_ssim_loss: Whether to use SSIM loss
    ssim_loss_weight: SSIM loss weight
    use_distortion_loss: Whether to use distortion loss
    distortion_loss_weight: Distortion loss weight
    use_pointwise_rgb_loss: Whether to use pointwise RGB loss
    pointwise_rgb_loss_weight: Pointwise RGB loss weight

    # New attributes for modern optimizations
    volume_size: tuple[int, int, int] = (128, 128, 128)
    feature_dim: int = 32
    num_planes: int = 3
    plane_channels: int = 16
    hidden_dim: int = 64
    num_layers: int = 4
    skip_connections: list[int] = (2,)
    activation: str = "relu"
    output_activation: str = "sigmoid"
    num_samples: int = 128
    num_importance_samples: int = 64
    learning_rate_decay_steps: int = 20000
    learning_rate_decay_mult: float = 0.1
    use_amp: bool = True
    grad_scaler_init_scale: float = 65536.0
    grad_scaler_growth_factor: float = 2.0
    grad_scaler_backoff_factor: float = 0.5
    grad_scaler_growth_interval: int = 2000
    use_non_blocking: bool = True
    set_grad_to_none: bool = True
    chunk_size: int = 8192
    cache_volume_samples: bool = True
    default_device: str = "cuda"
    pin_memory: bool = True
    batch_size: int = 4096
    num_workers: int = 4
    checkpoint_dir: str = "checkpoints"
    save_every_n_steps: int = 1000
    keep_last_n_checkpoints: int = 5

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/core.py`

#### æ–¹æ³• (Methods)

##### `checkpoint_path(self) -> Path`

Get checkpoint directory as Path object.

---



### SVRasterDataset

SVRaster dataset with modern PyTorch features.

Features:
- Efficient data loading and preprocessing
- Memory-optimized ray generation
- Automatic mixed precision support
- CUDA acceleration with CPU fallback
- Flexible data augmentation

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/dataset.py`

#### æ–¹æ³• (Methods)

##### `__init__(self, config: SVRasterDatasetConfig, split: str = 'train')`

Initialize dataset.

Args:
    config: Dataset configuration
    split: Dataset split ("train", "val", or "test")

---

##### `get_dataset_info(self) -> dict[str, Any]`

Get dataset information.

---



### SVRasterDatasetConfig

SVRaster dataset configuration.

Attributes:
    data_dir: Data directory path
    image_width: Image width
    image_height: Image height
    camera_angle_x: Camera horizontal FoV in radians
    train_split: Training split ratio
    val_split: Validation split ratio
    test_split: Test split ratio
    downscale_factor: Image downscale factor
    color_space: Color space ("linear" or "srgb")
    num_rays_train: Number of rays per training batch
    num_rays_val: Number of rays per validation batch
    patch_size: Size of image patches for ray sampling

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/dataset.py`



### SVRasterGPU

Enhanced GPU-optimized SVRaster model using CUDA kernels and advanced algorithms

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/cuda/svraster_gpu.py`

#### æ–¹æ³• (Methods)

##### `__init__(self, config)`

*æš‚æ— æ–‡æ¡£*

---

##### `adaptive_subdivision(self, subdivision_criteria: torch.Tensor) -> None`

Adaptively subdivide voxels based on criteria

---

##### `benchmark_performance(self, num_rays: int = 1000, num_iterations: int = 10) -> Dict[str, float]`

æ€§èƒ½åŸºå‡†æµ‹è¯•

Args:
    num_rays: æµ‹è¯•å…‰çº¿æ•°é‡
    num_iterations: æµ‹è¯•è¿­ä»£æ¬¡æ•°
    
Returns:
    æ€§èƒ½ç»Ÿè®¡ç»“æœ

---

##### `export_performance_report(self, filepath: str) -> None`

å¯¼å‡ºæ€§èƒ½æŠ¥å‘Š

---

##### `forward(self, ray_origins: torch.Tensor, ray_directions: torch.Tensor) -> Dict[str, torch.Tensor]`

Forward pass using GPU-optimized kernels

---

##### `get_voxel_statistics(self) -> Dict[str, Any]`

Get statistics about voxel distribution

---

##### `optimize_for_production(self) -> None`

ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–

---

##### `parameters(self)`

Return all trainable parameters as a generator (similar to nn.Module)

---

##### `print_performance_stats(self)`

Print performance statistics

---

##### `voxel_pruning(self, pruning_threshold: Optional[float] = None) -> None`

Prune low-density voxels

---



### SVRasterGPUTrainer

GPU-optimized trainer for SVRaster with modern PyTorch features.

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/cuda/svraster_gpu.py`

#### æ–¹æ³• (Methods)

##### `__init__(self, model: SVRasterGPU, config: SVRasterConfig)`

*æš‚æ— æ–‡æ¡£*

---

##### `save_checkpoint(self, filepath: str)`

Save checkpoint

---

##### `train_step(self, batch: dict[str, torch.Tensor]) -> dict[str, float]`

Perform a single training step.

---



### SVRasterLoss

Modern loss functions for SVRaster.

Features:
- Multiple loss terms with configurable weights
- SSIM loss for perceptual quality
- Distortion loss for geometry regularization
- Opacity regularization
- Pointwise RGB loss

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/core.py`

#### æ–¹æ³• (Methods)

##### `__call__(self, outputs: dict[str, torch.Tensor], targets: dict[str, torch.Tensor], model: SVRasterModel | None = None) -> dict[str, torch.Tensor]`

Compute all loss terms.

Args:
    outputs: Model outputs
    targets: Ground truth targets
    model: Optional model for regularization

Returns:
    Dictionary containing all loss terms and total loss

---

##### `__init__(self, config: SVRasterConfig)`

Initialize loss functions.

Args:
    config: Model configuration

---



### SVRasterModel

SVRaster model with modern PyTorch features.

Features:
- Efficient sparse voxel representation
- Automatic mixed precision training
- Memory-optimized operations
- CUDA acceleration with CPU fallback
- Real-time rendering capabilities

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/core.py`

#### æ–¹æ³• (Methods)

##### `__init__(self, config: SVRasterConfig)`

*æš‚æ— æ–‡æ¡£*

---

##### `evaluate(self, batch: dict[str, torch.Tensor]) -> dict[str, torch.Tensor]`

Evaluate model with modern optimizations.

Args:
    batch: Dictionary containing evaluation data

Returns:
    Dictionary containing evaluation metrics

---

##### `forward(self, ray_origins: torch.Tensor, ray_directions: torch.Tensor, camera_params: dict[str, torch.Tensor] | None = None) -> dict[str, torch.Tensor]`

Forward pass with modern optimizations.

Args:
    ray_origins: Ray origins [N, 3]
    ray_directions: Ray directions [N, 3]
    camera_params: Optional camera parameters

Returns:
    Dictionary containing rendered outputs

---

##### `render_image(self, camera_pose: torch.Tensor, camera_intrinsics: torch.Tensor, image_size: tuple[int, int], device: torch.device | None = None) -> dict[str, torch.Tensor]`

Render a full image efficiently.

Args:
    camera_pose: Camera-to-world transform [4, 4]
    camera_intrinsics: Camera intrinsics [3, 3]
    image_size: Output image size (H, W)
    device: Optional device to render on

Returns:
    Dictionary containing rendered image and auxiliary outputs

---

##### `train_step(self, batch: dict[str, torch.Tensor], optimizer: torch.optim.Optimizer) -> dict[str, torch.Tensor]`

Perform a single training step with modern optimizations.

Args:
    batch: Dictionary containing training data
    optimizer: PyTorch optimizer

Returns:
    Dictionary containing loss values

---



### SVRasterOptimizedKernels

SVRasterä¼˜åŒ–æ ¸å¿ƒç®—æ³•é›†åˆ
å®ç°é«˜æ•ˆçš„ä½“ç´ éå†ã€Mortonç æ’åºå’Œå†…å­˜ç®¡ç†

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/cuda/svraster_optimized_kernels.py`

#### æ–¹æ³• (Methods)

##### `__init__(self, device: torch.device)`

*æš‚æ— æ–‡æ¡£*

---

##### `cleanup_memory_pool(self)`

æ¸…ç†å†…å­˜æ± 

---

##### `get_performance_stats(self) -> Dict[str, float]`

è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯

---

##### `memory_efficient_allocation(self, size: int, dtype: torch.dtype = torch.float32) -> torch.Tensor`

å†…å­˜é«˜æ•ˆçš„å¼ é‡åˆ†é…
ä½¿ç”¨å†…å­˜æ± é¿å…é¢‘ç¹çš„åˆ†é…å’Œé‡Šæ”¾

---

##### `optimized_morton_sorting(self, positions: torch.Tensor, scene_bounds: torch.Tensor, precision_bits: int = 21) -> torch.Tensor`

ä¼˜åŒ–çš„Mortonç è®¡ç®—å’Œæ’åº

Args:
    positions: ä½ç½®åæ ‡ [N, 3]
    scene_bounds: åœºæ™¯è¾¹ç•Œ [6] (min_x, min_y, min_z, max_x, max_y, max_z)
    precision_bits: ç²¾åº¦ä½æ•°
    
Returns:
    Mortonç  [N]

---

##### `optimized_ray_voxel_intersection(self, ray_origins: torch.Tensor, ray_directions: torch.Tensor, voxel_positions: torch.Tensor, voxel_sizes: torch.Tensor, use_spatial_hash: bool = True) -> Dict[str, torch.Tensor]`

ä¼˜åŒ–çš„å…‰çº¿-ä½“ç´ ç›¸äº¤æµ‹è¯•

Args:
    ray_origins: å…‰çº¿èµ·ç‚¹ [N, 3]
    ray_directions: å…‰çº¿æ–¹å‘ [N, 3]
    voxel_positions: ä½“ç´ ä½ç½® [V, 3]
    voxel_sizes: ä½“ç´ å¤§å° [V]
    use_spatial_hash: æ˜¯å¦ä½¿ç”¨ç©ºé—´å“ˆå¸ŒåŠ é€Ÿ
    
Returns:
    ç›¸äº¤ç»“æœå­—å…¸

---

##### `reset_performance_counters(self)`

é‡ç½®æ€§èƒ½è®¡æ•°å™¨

---



### SVRasterRenderer

SVRaster æ¸²æŸ“å™¨

è´Ÿè´£åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å¹¶è¿›è¡Œé«˜è´¨é‡æ¸²æŸ“

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/renderer.py`

#### æ–¹æ³• (Methods)

##### `__init__(self, config: SVRasterRendererConfig)`

*æš‚æ— æ–‡æ¡£*

---

##### `get_model_info(self) -> Dict[str, Any]`

è·å–æ¨¡å‹ä¿¡æ¯

Returns:
    æ¨¡å‹ä¿¡æ¯å­—å…¸

---

##### `interactive_render(self, initial_pose: torch.Tensor, intrinsics: torch.Tensor, image_size: Optional[Tuple[int, int]] = None) -> InteractiveRenderer`

å¯åŠ¨äº¤äº’å¼æ¸²æŸ“æ¨¡å¼

Args:
    initial_pose: åˆå§‹ç›¸æœºä½å§¿
    intrinsics: ç›¸æœºå†…å‚
    image_size: å›¾åƒå°ºå¯¸

Returns:
    äº¤äº’å¼æ¸²æŸ“å™¨å®ä¾‹

---

##### `load_model(self, checkpoint_path: Union[str, Path]) -> None`

åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹

Args:
    checkpoint_path: æ¨¡å‹æ£€æŸ¥ç‚¹è·¯å¾„

---

##### `render_360_video(self, center: torch.Tensor, radius: float, intrinsics: torch.Tensor, num_frames: int = 120, output_path: Union[str, Path] = '360_video.mp4', fps: int = 30) -> str`

æ¸²æŸ“ 360 åº¦ç¯ç»•è§†é¢‘

Args:
    center: ç¯ç»•ä¸­å¿ƒç‚¹ [3]
    radius: ç¯ç»•åŠå¾„
    intrinsics: ç›¸æœºå†…å‚
    num_frames: è§†é¢‘å¸§æ•°
    output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
    fps: å¸§ç‡

Returns:
    è§†é¢‘æ–‡ä»¶è·¯å¾„

---

##### `render_path(self, camera_poses: List[torch.Tensor], intrinsics: torch.Tensor, output_dir: Union[str, Path], image_size: Optional[Tuple[int, int]] = None, save_video: bool = True, fps: int = 30) -> List[str]`

æ¸²æŸ“ç›¸æœºè·¯å¾„

Args:
    camera_poses: ç›¸æœºä½å§¿åˆ—è¡¨
    intrinsics: ç›¸æœºå†…å‚
    output_dir: è¾“å‡ºç›®å½•
    image_size: å›¾åƒå°ºå¯¸
    save_video: æ˜¯å¦ä¿å­˜è§†é¢‘
    fps: è§†é¢‘å¸§ç‡

Returns:
    ç”Ÿæˆçš„å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨

---

##### `render_single_view(self, camera_pose: torch.Tensor, intrinsics: torch.Tensor, image_size: Optional[Tuple[int, int]] = None) -> Dict[str, torch.Tensor]`

æ¸²æŸ“å•ä¸ªè§†è§’

Args:
    camera_pose: ç›¸æœºä½å§¿çŸ©é˜µ [4, 4] (world to camera)
    intrinsics: ç›¸æœºå†…å‚çŸ©é˜µ [3, 3] æˆ– [4, 4]
    image_size: å›¾åƒå°ºå¯¸ (width, height)ï¼ŒNone æ—¶ä½¿ç”¨é…ç½®ä¸­çš„å°ºå¯¸

Returns:
    æ¸²æŸ“ç»“æœå­—å…¸ï¼ŒåŒ…å« 'rgb', 'depth' ç­‰

---



### SVRasterRendererConfig

SVRaster æ¸²æŸ“å™¨é…ç½®

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/renderer.py`

#### æ–¹æ³• (Methods)



### SVRasterTrainer

Main trainer class for SVRaster model.

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/trainer.py`

#### æ–¹æ³• (Methods)

##### `__init__(self, model_config: SVRasterConfig, trainer_config: SVRasterTrainerConfig, train_dataset: SVRasterDataset, val_dataset: Optional[SVRasterDataset] = None) -> None`

*æš‚æ— æ–‡æ¡£*

---

##### `load_checkpoint(self, checkpoint_path: str)`

Load model checkpoint.

---

##### `train(self)`

Main training loop.

---



### SVRasterTrainerConfig

Configuration for SVRaster trainer.

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/trainer.py`

#### æ–¹æ³• (Methods)



### VoxelRasterizer

ä½“ç´ å…‰æ …åŒ–å™¨

å®ç°äº†åŸºäºå…‰çº¿æŠ•å°„çš„ä½“ç´ å…‰æ …åŒ–ç®—æ³•ï¼Œæ”¯æŒè‡ªé€‚åº”é‡‡æ ·å’Œæ·±åº¦å‰¥ç¦»ã€‚
ä¸åŒ…å«ä»»ä½•å¯è®­ç»ƒå‚æ•°ï¼Œåªè´Ÿè´£æ¸²æŸ“è¿‡ç¨‹ã€‚

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/core.py`

#### æ–¹æ³• (Methods)

##### `__call__(self, voxels: dict[str, torch.Tensor], ray_origins: torch.Tensor, ray_directions: torch.Tensor, camera_params: Optional[dict[str, torch.Tensor]] = None) -> dict[str, torch.Tensor]`

æ‰§è¡Œå…‰æ …åŒ–è¿‡ç¨‹

Args:
    voxels: åŒ…å«ä½“ç´ å±æ€§çš„å­—å…¸
    ray_origins: å…‰çº¿èµ·ç‚¹ [N, 3]
    ray_directions: å…‰çº¿æ–¹å‘ [N, 3]
    camera_params: å¯é€‰çš„ç›¸æœºå‚æ•°

Returns:
    åŒ…å«æ¸²æŸ“ç»“æœçš„å­—å…¸

---

##### `__init__(self, config: SVRasterConfig)`

*æš‚æ— æ–‡æ¡£*

---



## ğŸ”§ å‡½æ•° (Functions)

### `compact1by2(n)`

Compact bits by removing two zeros between each bit.

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/morton_utils.py`

---

### `compute_morton_order(positions: torch.Tensor, scene_bounds: tuple[float, float, float, float, float, float], grid_resolution: int) -> torch.Tensor`

Compute Morton order for a set of 3D positions.

Args:
    positions: Tensor of 3D positions [N, 3]
    scene_bounds: Scene bounds (min_x, min_y, min_z, max_x, max_y, max_z)
    grid_resolution: Grid resolution for discretization
    
Returns:
    Morton codes for the positions [N]

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/morton_utils.py`

---

### `compute_octree_level(voxel_size: float, base_size: float) -> int`

Compute octree level based on voxel size.

Args:
    voxel_size: Size of the voxel
    base_size: Base voxel size at level 0
    
Returns:
    Octree level

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/octree_utils.py`

---

### `compute_ray_aabb_intersection(ray_origin: torch.Tensor, ray_direction: torch.Tensor, box_min: torch.Tensor, box_max: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]`

Compute ray-AABB intersection.

Args:
    ray_origin: Ray origin [3] or [N, 3]
    ray_direction: Ray direction [3] or [N, 3]
    box_min: Box minimum corner [3] or [M, 3]
    box_max: Box maximum corner [3] or [M, 3]
    
Returns:
    tuple of (t_near, t_far, valid_mask)

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/rendering_utils.py`

---

### `compute_ray_samples(ray_origins: torch.Tensor, ray_directions: torch.Tensor, near: float, far: float, num_samples: int = 64, perturb: bool = True) -> dict[str, torch.Tensor]`

Compute sample points along rays.

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/rendering_utils.py`

---

### `compute_ssim(img1: torch.Tensor, img2: torch.Tensor, window_size: int = 11) -> torch.Tensor`

Compute SSIM between two images

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/core.py`

---

### `compute_voxel_bounds(voxel_positions: torch.Tensor, voxel_sizes: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]`

Compute bounding boxes for voxels.

Args:
    voxel_positions: Voxel center positions [N, 3]
    voxel_sizes: Voxel sizes [N]
    
Returns:
    tuple of (box_min, box_max) each [N, 3]

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/voxel_utils.py`

---

### `create_svraster_dataloader(config: SVRasterDatasetConfig, split: str = 'train', batch_size: int = 1, shuffle: bool = True, num_workers: int = 4) -> DataLoader`

Create a DataLoader for SVRaster dataset.

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/dataset.py`

---

### `create_svraster_dataset(config: SVRasterDatasetConfig, split: str = 'train') -> SVRasterDataset`

Create a SVRaster dataset.

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/dataset.py`

---

### `create_svraster_trainer(model_config: SVRasterConfig, trainer_config: SVRasterTrainerConfig, train_dataset: SVRasterDataset, val_dataset: Optional[SVRasterDataset] = None) -> SVRasterTrainer`

Create a SVRaster trainer.

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/trainer.py`

---

### `depth_peeling(voxel_positions: torch.Tensor, voxel_sizes: torch.Tensor, ray_origin: torch.Tensor, ray_direction: torch.Tensor, num_layers: int = 4) -> list[torch.Tensor]`

Perform depth peeling for correct transparency rendering.

Args:
    voxel_positions: Voxel positions [N, 3]
    voxel_sizes: Voxel sizes [N]
    ray_origin: Ray origin [3]
    ray_direction: Ray direction [3]
    num_layers: Number of depth layers to peel
    
Returns:
    list of voxel indices for each depth layer

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/rendering_utils.py`

---

### `eval_sh_basis(degree: int, dirs: torch.Tensor) -> torch.Tensor`

è®¡ç®—çƒè°å‡½æ•°åŸºï¼ˆæ”¯æŒ 0~3 é˜¶ï¼‰ï¼Œè¾“å…¥æ–¹å‘ shape [..., 3]ï¼Œè¾“å‡º shape [..., num_sh_coeffs]

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/core.py`

---

### `get_compute_capability()`

*æš‚æ— æ–‡æ¡£*

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/cuda/setup.py`

---

### `get_cuda_version()`

*æš‚æ— æ–‡æ¡£*

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/cuda/setup.py`

---

### `get_octree_neighbors(voxel_position: torch.Tensor, voxel_size: float, all_positions: torch.Tensor, all_sizes: torch.Tensor) -> torch.Tensor`

Find neighboring voxels in the octree.

Args:
    voxel_position: Position of the query voxel [3]
    voxel_size: Size of the query voxel
    all_positions: All voxel positions [N, 3]
    all_sizes: All voxel sizes [N]
    
Returns:
    Indices of neighboring voxels

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/octree_utils.py`

---

### `main()`

*æš‚æ— æ–‡æ¡£*

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/cuda/setup.py`

---

### `morton_decode_3d(morton_code: int) -> tuple[int, int, int]`

Decode Morton code back to 3D coordinates.

Args:
    morton_code: Morton code as integer
    
Returns:
    tuple of (x, y, z) coordinates

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/morton_utils.py`

---

### `morton_decode_batch(morton_codes: torch.Tensor) -> torch.Tensor`

Decode batch of Morton codes back to 3D coordinates.

Args:
    morton_codes: Tensor of Morton codes [N]
    
Returns:
    Tensor of coordinates [N, 3]

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/morton_utils.py`

---

### `morton_encode_3d(x: int, y: int, z: int) -> int`

Encode 3D coordinates into Morton code.

æ”¹è¿›çš„ Morton ç¼–ç å®ç°ï¼Œæ”¯æŒæ›´é«˜çš„åˆ†è¾¨ç‡ï¼š
- æ¯ä¸ªåæ ‡åˆ†é‡ä½¿ç”¨ 21 ä½ï¼Œæ€»å…±æ”¯æŒ 2097151Â³ ä¸ªä½ç½®
- å®Œå…¨æ»¡è¶³ SVRaster çš„ 65536Â³ åˆ†è¾¨ç‡éœ€æ±‚

Args:
    x, y, z: 3D coordinates
    
Returns:
    Morton code as integer

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/morton_utils.py`

---

### `morton_encode_batch(coords: torch.Tensor) -> torch.Tensor`

Encode batch of 3D coordinates into Morton codes.

ä½¿ç”¨å‘é‡åŒ–æ“ä½œè¿›è¡Œæ‰¹é‡ Morton ç è®¡ç®—ï¼Œæé«˜æ€§èƒ½ã€‚

Args:
    coords: Tensor of shape [N, 3] with integer coordinates
    
Returns:
    Tensor of Morton codes [N]

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/morton_utils.py`

---

### `octree_pruning(voxel_densities: torch.Tensor, threshold: float = 0.001) -> torch.Tensor`

Create pruning mask for low-density voxels.

Args:
    voxel_densities: Voxel density values [N]
    threshold: Pruning threshold
    
Returns:
    Boolean mask for voxels to keep [N]

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/octree_utils.py`

---

### `octree_subdivision(voxel_positions: torch.Tensor, voxel_sizes: torch.Tensor, subdivision_mask: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]`

Subdivide voxels into 8 child voxels.

Args:
    voxel_positions: Voxel center positions [N, 3]
    voxel_sizes: Voxel sizes [N]
    subdivision_mask: Boolean mask for voxels to subdivide [N]
    
Returns:
    tuple of (child_positions, child_sizes)

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/octree_utils.py`

---

### `part1by2(n)`

*æš‚æ— æ–‡æ¡£*

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/core.py`

---

### `part1by2(n)`

Separate bits by inserting two zeros between each bit.

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/morton_utils.py`

---

### `part1by2_vectorized(n)`

*æš‚æ— æ–‡æ¡£*

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/core.py`

---

### `part1by2_vectorized(n)`

*æš‚æ— æ–‡æ¡£*

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/morton_utils.py`

---

### `ray_direction_dependent_ordering(voxel_positions: torch.Tensor, morton_codes: torch.Tensor, ray_direction: torch.Tensor) -> torch.Tensor`

Sort voxels using ray direction-dependent Morton ordering.

Args:
    voxel_positions: Voxel positions [N, 3]
    morton_codes: Morton codes for voxels [N]
    ray_direction: Mean ray direction [3]
    
Returns:
    Sort indices for correct depth ordering

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/rendering_utils.py`

---

### `render_rays(ray_origins: torch.Tensor, ray_directions: torch.Tensor, near: float, far: float, num_samples: int = 64, perturb: bool = True) -> dict[str, torch.Tensor]`

Render rays using volume rendering.

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/rendering_utils.py`

---

### `sort_by_morton_order(positions: torch.Tensor, scene_bounds: tuple[float, float, float, float, float, float], grid_resolution: int) -> tuple[torch.Tensor, torch.Tensor]`

Sort positions by Morton order.

Args:
    positions: Tensor of 3D positions [N, 3]
    scene_bounds: Scene bounds
    grid_resolution: Grid resolution for discretization
    
Returns:
    tuple of (sorted_positions, sort_indices)

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/morton_utils.py`

---

### `volume_rendering_integration(densities: torch.Tensor, colors: torch.Tensor, distances: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]`

Perform volume rendering integration.

Args:
    densities: Density values along ray [N]
    colors: Color values along ray [N, 3]
    distances: Distance intervals [N]
    
Returns:
    tuple of (integrated_color, integrated_alpha)

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/rendering_utils.py`

---

### `voxel_pruning(voxel_densities: torch.Tensor, voxel_positions: torch.Tensor, voxel_sizes: torch.Tensor, threshold: float = 0.001) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]`

Prune voxels with low density.

Args:
    voxel_densities: Voxel density values [N]
    voxel_positions: Voxel positions [N, 3]
    voxel_sizes: Voxel sizes [N]
    threshold: Pruning threshold
    
Returns:
    tuple of (pruned_densities, pruned_positions, pruned_sizes)

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/voxel_utils.py`

---

### `voxel_to_world_coords(voxel_coords: torch.Tensor, scene_bounds: tuple[float, float, float, float, float, float], grid_resolution: int) -> torch.Tensor`

Convert voxel coordinates to world coordinates.

Args:
    voxel_coords: Voxel coordinates [N, 3]
    scene_bounds: Scene bounds (min_x, min_y, min_z, max_x, max_y, max_z)
    grid_resolution: Grid resolution
    
Returns:
    World coordinates [N, 3]

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/voxel_utils.py`

---

### `world_to_voxel_coords(world_coords: torch.Tensor, scene_bounds: tuple[float, float, float, float, float, float], grid_resolution: int) -> torch.Tensor`

Convert world coordinates to voxel coordinates.

Args:
    world_coords: World coordinates [N, 3]
    scene_bounds: Scene bounds (min_x, min_y, min_z, max_x, max_y, max_z)
    grid_resolution: Grid resolution
    
Returns:
    Voxel coordinates [N, 3]

**æ¨¡å—è·¯å¾„**: `src/nerfs/svraster/utils/voxel_utils.py`

---


---
*æœ¬æ–‡æ¡£ç”Ÿæˆäº 2025-07-05 23:36:46*
