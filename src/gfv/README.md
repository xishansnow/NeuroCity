# GFV (Global Feature Vector) Library

A high-performance global feature vector library based on multi-resolution hash encoding for neural graphics primitives and spatial data processing.

## ç‰¹æ€§ (Features)

- ğŸŒ **å…¨çƒåœ°ç†åæ ‡æ”¯æŒ** - Global geographic coordinate support
- ğŸ”¥ **å¤šåˆ†è¾¨ç‡å“ˆå¸Œç¼–ç ** - Multi-resolution hash encoding
- ğŸ“Š **åˆ†å±‚ç‰¹å¾è¡¨ç¤º** - Hierarchical feature representation
- âš¡ **é«˜æ•ˆæŸ¥è¯¢å’Œæ›´æ–°** - Efficient query and update operations
- ğŸ’¾ **åˆ†å¸ƒå¼å­˜å‚¨æ”¯æŒ** - Distributed storage support
- ğŸ¯ **PyTorch Lightning é›†æˆ** - PyTorch Lightning integration
- ğŸ“ˆ **ä¸°å¯Œçš„å¯è§†åŒ–å·¥å…·** - Rich visualization tools

## å®‰è£… (Installation)

```bash
# ä»æºç å®‰è£…
cd NeuroCity
pip install -e .

# æˆ–ç›´æ¥å¯¼å…¥ä½¿ç”¨
from src.gfv import GlobalHashConfig, GlobalFeatureLibrary
```

## ä¾èµ– (Dependencies)

```
torch >= 1.9.0
numpy >= 1.20.0
matplotlib >= 3.3.0
mercantile >= 1.2.0
pyproj >= 3.0.0
sqlite3 (built-in)
tqdm >= 4.62.0
scipy >= 1.7.0
seaborn >= 0.11.0
plotly >= 5.0.0 (optional, for interactive visualizations)
pytorch-lightning >= 1.5.0 (optional, for Lightning training)
h5py >= 3.0.0 (optional, for HDF5 support)
```

## å¿«é€Ÿå¼€å§‹ (Quick Start)

### åŸºç¡€ä½¿ç”¨

```python
from src.gfv import GlobalHashConfig, GlobalFeatureLibrary

# 1. åˆ›å»ºé…ç½®
config = GlobalHashConfig(
    num_levels=16,
    max_hash=2**14,
    base_resolution=16,
    finest_resolution=512,
    feature_dim=2,
    db_path="global_features.db"
)

# 2. åˆ›å»ºå…¨çƒç‰¹å¾åº“
gfv_library = GlobalFeatureLibrary(config)

# 3. æŸ¥è¯¢ç‰¹å¾
beijing_features = gfv_library.get_feature_vector(39.9042, 116.4074, zoom=10)
print(f"åŒ—äº¬ç‰¹å¾ç»´åº¦: {beijing_features.shape}")

# 4. è·å–åŒºåŸŸç‰¹å¾
bounds = (116.0, 39.5, 117.0, 40.5)  # åŒ—äº¬åŒºåŸŸ
region_features = gfv_library.get_region_features(bounds, zoom=8)
print(f"åŒºåŸŸåŒ…å« {len(region_features)} ä¸ªç“¦ç‰‡")
```

### è®­ç»ƒç¤ºä¾‹

```python
from src.gfv import GlobalFeatureDataset, GFVTrainer

# 1. å‡†å¤‡è®­ç»ƒæ•°æ®
coords = [(39.9042, 116.4074), (31.2304, 121.4737)]  # åŒ—äº¬, ä¸Šæµ·
features = [np.random.randn(64), np.random.randn(64)]  # ç¤ºä¾‹ç‰¹å¾

# 2. åˆ›å»ºæ•°æ®é›†
dataset = GlobalFeatureDataset(coords, features)

# 3. åˆ›å»ºè®­ç»ƒå™¨
trainer_config = {
    'learning_rate': 1e-3,
    'num_epochs': 100,
    'batch_size': 32
}
trainer = GFVTrainer(gfv_library, trainer_config)

# 4. è®­ç»ƒæ¨¡å‹
results = trainer.train(dataset, save_path="gfv_model.pth")
```

### PyTorch Lightning è®­ç»ƒ

```python
from src.gfv import GFVLightningModule
import pytorch_lightning as pl

# 1. åˆ›å»º Lightning æ¨¡å—
lightning_module = GFVLightningModule(
    config=config,
    learning_rate=1e-3
)

# 2. åˆ›å»ºè®­ç»ƒå™¨
trainer = pl.Trainer(
    max_epochs=100,
    accelerator='gpu',
    devices=1
)

# 3. è®­ç»ƒ
trainer.fit(lightning_module, train_dataloader, val_dataloader)
```

## æ ¸å¿ƒç»„ä»¶ (Core Components)

### 1. GlobalHashConfig
å…¨çƒå“ˆå¸Œç¼–ç é…ç½®ç±»ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„å‚æ•°è®¾ç½®ã€‚

```python
config = GlobalHashConfig(
    num_levels=16,              # å“ˆå¸Œè¡¨å±‚æ•°
    max_hash=2**14,            # æœ€å¤§å“ˆå¸Œå€¼
    base_resolution=16,         # åŸºç¡€åˆ†è¾¨ç‡
    finest_resolution=512,      # æœ€ç»†åˆ†è¾¨ç‡
    feature_dim=2,             # æ¯å±‚ç‰¹å¾ç»´åº¦
    global_bounds=(-180, -90, 180, 90),  # å…¨çƒè¾¹ç•Œ
    tile_size=256,             # ç“¦ç‰‡å¤§å°
    max_zoom=18,               # æœ€å¤§ç¼©æ”¾çº§åˆ«
    db_path="global_features.db",  # æ•°æ®åº“è·¯å¾„
    cache_size=10000           # ç¼“å­˜å¤§å°
)
```

### 2. MultiResolutionHashEncoding
å¤šåˆ†è¾¨ç‡å“ˆå¸Œç¼–ç ç½‘ç»œï¼Œæ”¯æŒç©ºé—´åæ ‡åˆ°ç‰¹å¾å‘é‡çš„æ˜ å°„ã€‚

```python
from src.gfv.core import MultiResolutionHashEncoding

encoder = MultiResolutionHashEncoding(config)
coords = torch.randn(100, 3)  # [N, 3] åæ ‡
features = encoder(coords)    # [N, total_feature_dim] ç‰¹å¾
```

### 3. GlobalFeatureDatabase
å…¨çƒç‰¹å¾æ•°æ®åº“ï¼Œæä¾›é«˜æ•ˆçš„å­˜å‚¨å’ŒæŸ¥è¯¢åŠŸèƒ½ã€‚

```python
from src.gfv.core import GlobalFeatureDatabase

database = GlobalFeatureDatabase(config)

# å­˜å‚¨ç‰¹å¾
database.store_features(x=100, y=200, zoom=10, features=features)

# æŸ¥è¯¢ç‰¹å¾  
features = database.query_features(lat=39.9042, lon=116.4074, zoom=10)

# è·å–ç»Ÿè®¡ä¿¡æ¯
stats = database.get_database_stats()
```

### 4. GlobalFeatureLibrary
å…¨çƒç‰¹å¾åº“ä¸»ç±»ï¼Œæä¾›å®Œæ•´çš„ç‰¹å¾ç®¡ç†åŠŸèƒ½ã€‚

```python
from src.gfv.core import GlobalFeatureLibrary

library = GlobalFeatureLibrary(config)

# è®­ç»ƒ
training_data = [(lat, lon, features), ...]
library.train_on_global_data(training_data, num_epochs=100)

# æŸ¥è¯¢
features = library.get_feature_vector(lat, lon, zoom=10)

# ä¿å­˜/åŠ è½½æ¨¡å‹
library.save_model("model.pth")
library.load_model("model.pth")
```

## æ•°æ®é›†ç±» (Dataset Classes)

### SDFDataset
```python
from src.gfv.dataset import SDFDataset

dataset = SDFDataset("sdf_data.npy")
coords, sdf_values = dataset[0]
```

### GlobalFeatureDataset
```python
from src.gfv.dataset import GlobalFeatureDataset

dataset = GlobalFeatureDataset(coords, features, zoom_levels)
sample = dataset[0]  # {'coords': ..., 'features': ..., 'zoom': ...}
```

### MultiScaleDataset
```python
from src.gfv.dataset import MultiScaleDataset

dataset = MultiScaleDataset(base_coords, zoom_levels=[8, 10, 12, 14])
```

## å·¥å…·å‡½æ•° (Utilities)

### åæ ‡è½¬æ¢
```python
from src.gfv.utils import lat_lon_to_tile, calculate_distance

# ç»çº¬åº¦è½¬ç“¦ç‰‡åæ ‡
tile_x, tile_y = lat_lon_to_tile(39.9042, 116.4074, zoom=10)

# è®¡ç®—è·ç¦»
distance = calculate_distance(39.9042, 116.4074, 31.2304, 121.4737)
```

### å¯è§†åŒ–
```python
from src.gfv.utils import plot_coverage_map, visualize_global_features

# ç»˜åˆ¶è¦†ç›–å›¾
plot_coverage_map(database_stats, save_path="coverage.png")

# å¯è§†åŒ–å…¨çƒç‰¹å¾
visualize_global_features(coords, features, save_path="features.png")
```

### æ•°æ®å¤„ç†
```python
from src.gfv.utils import load_sdf_data, save_feature_cache

# åŠ è½½ SDF æ•°æ®
coords, sdf_values = load_sdf_data("data.npy")

# ä¿å­˜ç‰¹å¾ç¼“å­˜
save_feature_cache(features_dict, "cache.npz")
```

## é«˜çº§åŠŸèƒ½ (Advanced Features)

### å¤šå°ºåº¦è®­ç»ƒ
```python
from src.gfv.trainer import GFVMultiScaleTrainer

multiscale_trainer = GFVMultiScaleTrainer(
    model=gfv_library,
    config={'progressive_training': True}
)

results = multiscale_trainer.train_multiscale(
    train_dataset=multiscale_dataset,
    save_path="multiscale_model.pth"
)
```

### äº¤äº’å¼å¯è§†åŒ–
```python
from src.gfv.utils import plot_interactive_map, create_dashboard

# åˆ›å»ºäº¤äº’å¼åœ°å›¾
fig = plot_interactive_map(coords, features)
fig.show()

# åˆ›å»ºç»¼åˆä»ªè¡¨æ¿
dashboard = create_dashboard(
    database_stats=stats,
    training_history=results,
    coords=coords,
    features=features
)
dashboard.show()
```

## æ€§èƒ½ä¼˜åŒ– (Performance Optimization)

### æ‰¹é‡æŸ¥è¯¢
```python
# æ‰¹é‡æŸ¥è¯¢æ¯”å•æ¬¡æŸ¥è¯¢æ›´é«˜æ•ˆ
batch_features = database.batch_query_features(coords_list, zoom=10)
```

### ç¼“å­˜ç­–ç•¥
```python
# è°ƒæ•´ç¼“å­˜å¤§å°ä»¥ä¼˜åŒ–å†…å­˜ä½¿ç”¨
config = GlobalHashConfig(cache_size=50000)  # å¢å¤§ç¼“å­˜
```

### GPU åŠ é€Ÿ
```python
# ä½¿ç”¨ GPU è¿›è¡Œå“ˆå¸Œç¼–ç è®¡ç®—
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
encoder = encoder.to(device)
```

## ç¤ºä¾‹é¡¹ç›® (Example Projects)

æŸ¥çœ‹ `src/gfv/example_usage.py` è·å–å®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹ï¼ŒåŒ…æ‹¬ï¼š

- åŸºç¡€ä½¿ç”¨ç¤ºä¾‹
- è®­ç»ƒç¤ºä¾‹
- å¤šå°ºåº¦ç‰¹å¾å¤„ç†
- å¯è§†åŒ–ç¤ºä¾‹
- æ€§èƒ½åˆ†æ

è¿è¡Œç¤ºä¾‹ï¼š
```bash
cd src/gfv
python example_usage.py
```

## API å‚è€ƒ (API Reference)

è¯¦ç»†çš„ API æ–‡æ¡£è¯·å‚è€ƒå„æ¨¡å—çš„ docstringï¼š

- `core.py` - æ ¸å¿ƒç»„ä»¶
- `dataset.py` - æ•°æ®é›†ç±»
- `trainer.py` - è®­ç»ƒå™¨ç»„ä»¶
- `utils/` - å·¥å…·å‡½æ•°åŒ…

## é…ç½®é€‰é¡¹ (Configuration Options)

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `num_levels` | int | 16 | å“ˆå¸Œè¡¨å±‚æ•° |
| `max_hash` | int | 16384 | æœ€å¤§å“ˆå¸Œå€¼ |
| `base_resolution` | int | 16 | åŸºç¡€åˆ†è¾¨ç‡ |
| `finest_resolution` | int | 512 | æœ€ç»†åˆ†è¾¨ç‡ |
| `feature_dim` | int | 2 | æ¯å±‚ç‰¹å¾ç»´åº¦ |
| `global_bounds` | tuple | (-180, -90, 180, 90) | å…¨çƒè¾¹ç•Œ |
| `tile_size` | int | 256 | ç“¦ç‰‡å¤§å° |
| `max_zoom` | int | 18 | æœ€å¤§ç¼©æ”¾çº§åˆ« |
| `db_path` | str | "global_features.db" | æ•°æ®åº“è·¯å¾„ |
| `cache_size` | int | 10000 | ç¼“å­˜å¤§å° |

## å¸¸è§é—®é¢˜ (FAQ)

### Q: å¦‚ä½•é€‰æ‹©åˆé€‚çš„å“ˆå¸Œè¡¨å±‚æ•°ï¼Ÿ
A: å“ˆå¸Œè¡¨å±‚æ•°å†³å®šäº†ç‰¹å¾çš„è¡¨ç¤ºèƒ½åŠ›ã€‚ä¸€èˆ¬å»ºè®®ï¼š
- å°è§„æ¨¡åœºæ™¯ï¼š8-12 å±‚
- ä¸­ç­‰è§„æ¨¡ï¼š12-16 å±‚  
- å¤§è§„æ¨¡å…¨çƒåœºæ™¯ï¼š16-20 å±‚

### Q: å¦‚ä½•ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½ï¼Ÿ
A: å‡ ä¸ªä¼˜åŒ–å»ºè®®ï¼š
1. ä½¿ç”¨æ‰¹é‡æŸ¥è¯¢è€Œéå•æ¬¡æŸ¥è¯¢
2. å¢å¤§ç¼“å­˜å¤§å°
3. ä½¿ç”¨é€‚å½“çš„ç¼©æ”¾çº§åˆ«
4. è€ƒè™‘ä½¿ç”¨ GPU åŠ é€Ÿ

### Q: æ•°æ®åº“æ–‡ä»¶è¿‡å¤§æ€ä¹ˆåŠï¼Ÿ
A: å¯ä»¥ï¼š
1. ä½¿ç”¨æ›´å°çš„ç‰¹å¾ç»´åº¦
2. å®šæœŸæ¸…ç†ä¸éœ€è¦çš„ç¼“å­˜
3. ä½¿ç”¨å‹ç¼©å­˜å‚¨æ ¼å¼ï¼ˆHDF5ï¼‰
4. åˆ†å¸ƒå¼å­˜å‚¨

## è®¸å¯è¯ (License)

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ LICENSE æ–‡ä»¶ã€‚

## è´¡çŒ® (Contributing)

æ¬¢è¿æäº¤ Issues å’Œ Pull Requestsï¼

## æ›´æ–°æ—¥å¿— (Changelog)

### v1.0.0
- åˆå§‹å‘å¸ƒ
- åŸºç¡€å…¨çƒç‰¹å¾å‘é‡åŠŸèƒ½
- å¤šåˆ†è¾¨ç‡å“ˆå¸Œç¼–ç 
- PyTorch Lightning æ”¯æŒ
- ä¸°å¯Œçš„å¯è§†åŒ–å·¥å…· 