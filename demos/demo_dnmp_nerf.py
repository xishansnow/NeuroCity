#!/usr/bin/env python3
"""
DNMP NeRF æ¼”ç¤ºè„šæœ¬

å±•ç¤ºDifferentiable Neural Mesh Primitive (DNMP) NeRFçš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- å¯å¾®åˆ†ç½‘æ ¼è¡¨ç¤º
- ç½‘æ ¼è‡ªåŠ¨ç¼–ç å™¨
- å…‰æ …åŒ–æ¸²æŸ“
- å‡ ä½•ä¸çº¹ç†è”åˆä¼˜åŒ–
"""

import sys
import os
import torch
import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, List, Optional, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from src.nerfs.dnmp_nerf.core import DNMPNeRF, DNMPNeRFConfig
    from src.nerfs.dnmp_nerf.mesh_autoencoder import MeshAutoencoder
    from src.nerfs.dnmp_nerf.rasterizer import DifferentiableRasterizer
    DNMP_NERF_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ DNMP NeRFæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    DNMP_NERF_AVAILABLE = False


class MockDNMPNeRFConfig:
    """æ¨¡æ‹ŸDNMP NeRFé…ç½®"""
    def __init__(self):
        self.mesh_resolution = 128
        self.latent_dim = 256
        self.encoder_layers = [512, 256, 128]
        self.decoder_layers = [128, 256, 512]
        self.texture_dim = 64
        self.use_mesh_autoencoder = True
        self.rasterization_size = 256
        self.scene_bounds = (-2.0, -2.0, -2.0, 2.0, 2.0, 2.0)


class MockMeshAutoencoder(torch.nn.Module):
    """æ¨¡æ‹Ÿç½‘æ ¼è‡ªåŠ¨ç¼–ç å™¨"""
    
    def __init__(self, config):
        super().__init__()
        self.config = config
        
        # ç¼–ç å™¨
        encoder_layers = []
        in_dim = config.mesh_resolution * 3  # é¡¶ç‚¹åæ ‡
        for hidden_dim in config.encoder_layers:
            encoder_layers.extend([
                torch.nn.Linear(in_dim, hidden_dim), torch.nn.ReLU()
            ])
            in_dim = hidden_dim
        encoder_layers.append(torch.nn.Linear(in_dim, config.latent_dim))
        self.encoder = torch.nn.Sequential(*encoder_layers)
        
        # è§£ç å™¨
        decoder_layers = []
        in_dim = config.latent_dim
        for hidden_dim in config.decoder_layers:
            decoder_layers.extend([
                torch.nn.Linear(in_dim, hidden_dim), torch.nn.ReLU()
            ])
            in_dim = hidden_dim
        decoder_layers.append(torch.nn.Linear(in_dim, config.mesh_resolution * 3))
        self.decoder = torch.nn.Sequential(*decoder_layers)
    
    def encode(self, vertices: torch.Tensor) -> torch.Tensor:
        """ç¼–ç ç½‘æ ¼é¡¶ç‚¹åˆ°æ½œåœ¨ç©ºé—´"""
        batch_size = vertices.shape[0]
        vertices_flat = vertices.view(batch_size, -1)
        return self.encoder(vertices_flat)
    
    def decode(self, latent: torch.Tensor) -> torch.Tensor:
        """ä»æ½œåœ¨ç©ºé—´è§£ç ç½‘æ ¼é¡¶ç‚¹"""
        batch_size = latent.shape[0]
        vertices_flat = self.decoder(latent)
        return vertices_flat.view(batch_size, self.config.mesh_resolution, 3)
    
    def forward(self, vertices: torch.Tensor) -> dict[str, torch.Tensor]:
        """è‡ªåŠ¨ç¼–ç å™¨å‰å‘ä¼ æ’­"""
        latent = self.encode(vertices)
        reconstructed = self.decode(latent)
        return {
            'latent': latent, 'reconstructed': reconstructed
        }


class MockDNMPNeRF(torch.nn.Module):
    """æ¨¡æ‹ŸDNMP NeRFæ¨¡å‹"""
    
    def __init__(self, config):
        super().__init__()
        self.config = config
        
        # ç½‘æ ¼è‡ªåŠ¨ç¼–ç å™¨
        if config.use_mesh_autoencoder:
            self.mesh_autoencoder = MockMeshAutoencoder(config)
        
        # çº¹ç†ç½‘ç»œ
        self.texture_network = torch.nn.Sequential(
            torch.nn.Linear(
                3 + config.latent_dim,
                config.texture_dim,
            )
        )
        
        # å‡ ä½•ç½‘ç»œ
        self.geometry_network = torch.nn.Sequential(
            torch.nn.Linear(
                3,
                128,
            )
        )
    
    def generate_mesh(self, batch_size: int = 1) -> torch.Tensor:
        """ç”Ÿæˆåˆå§‹ç½‘æ ¼"""
        # ç®€åŒ–ï¼šç”Ÿæˆçƒå½¢ç½‘æ ¼é¡¶ç‚¹
        vertices = []
        for i in range(self.config.mesh_resolution):
            theta = 2 * np.pi * i / self.config.mesh_resolution
            vertex = torch.tensor([
                np.cos(theta), np.sin(theta), 0.0
            ])
            vertices.append(vertex)
        
        mesh = torch.stack(vertices).unsqueeze(0).repeat(batch_size, 1, 1)
        return mesh
    
    def forward(
        self,
        positions: torch.Tensor,
        mesh: Optional[torch.Tensor] = None,
    )
        """å‰å‘ä¼ æ’­"""
        batch_size = positions.shape[0]
        
        if mesh is None:
            mesh = self.generate_mesh(batch_size).to(positions.device)
        
        # ç½‘æ ¼ç¼–ç 
        if self.config.use_mesh_autoencoder:
            mesh_output = self.mesh_autoencoder(mesh)
            latent = mesh_output['latent']
            reconstructed_mesh = mesh_output['reconstructed']
        else:
            latent = torch.randn(batch_size, self.config.latent_dim).to(positions.device)
            reconstructed_mesh = mesh
        
        # å‡ ä½•è®¡ç®—
        sdf_values = self.geometry_network(positions)
        
        # çº¹ç†è®¡ç®—
        latent_expanded = latent.unsqueeze(1).expand(-1, positions.shape[1], -1)
        texture_input = torch.cat([positions, latent_expanded], dim=-1)
        colors = self.texture_network(texture_input)
        
        return {
            'sdf': sdf_values.squeeze(
                -1,
            )
        }


def create_mesh_dataset(
    num_meshes: int = 100,
    mesh_resolution: int = 64,
)
    """åˆ›å»ºç½‘æ ¼æ•°æ®é›†"""
    print(f"ğŸ“Š åˆ›å»ºç½‘æ ¼æ•°æ®é›†: {num_meshes}ä¸ªç½‘æ ¼, åˆ†è¾¨ç‡{mesh_resolution}")
    
    meshes = []
    colors = []
    
    for i in range(num_meshes):
        # ç”Ÿæˆå˜å½¢çš„çƒå½¢ç½‘æ ¼
        vertices = []
        mesh_colors = []
        
        for j in range(mesh_resolution):
            theta = 2 * np.pi * j / mesh_resolution
            phi = np.pi * (i / num_meshes - 0.5)  # å˜åŒ–é«˜åº¦
            
            # æ·»åŠ ä¸€äº›å½¢å˜
            radius = 1.0 + 0.3 * np.sin(4 * theta)
            
            vertex = torch.tensor([
                radius * np.cos(
                    theta,
                )
            ])
            
            # åŸºäºä½ç½®çš„é¢œè‰²
            color = torch.sigmoid(vertex + 0.5)
            
            vertices.append(vertex)
            mesh_colors.append(color)
        
        mesh = torch.stack(vertices)
        mesh_color = torch.stack(mesh_colors)
        
        meshes.append(mesh)
        colors.append(mesh_color.mean(0))  # å¹³å‡é¢œè‰²ä½œä¸ºæ•´ä½“é¢œè‰²
    
    return {
        'meshes': torch.stack(
            meshes,
        )
    }


def train_dnmp_nerf(
    model: MockDNMPNeRF,
    dataset: dict[str,
    torch.Tensor],
    num_epochs: int = 200,
)
    """è®­ç»ƒDNMP NeRFæ¨¡å‹"""
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒDNMP NeRFæ¨¡å‹")
    print(f"ğŸ“ˆ è®­ç»ƒæ•°æ®: {len(dataset['meshes'])} ä¸ªç½‘æ ¼")
    print(f"ğŸ”„ è®­ç»ƒè½®æ¬¡: {num_epochs}")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    model = model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    
    meshes = dataset['meshes'].to(device)
    colors = dataset['colors'].to(device)
    positions = dataset['positions'].to(device)
    
    training_history = []
    
    for epoch in range(num_epochs):
        # éšæœºé‡‡æ ·
        batch_size = 16
        mesh_indices = torch.randperm(len(meshes))[:batch_size]
        pos_indices = torch.randperm(len(positions))[:batch_size * 50]
        
        batch_meshes = meshes[mesh_indices]
        batch_colors = colors[mesh_indices]
        batch_positions = positions[pos_indices].unsqueeze(0).repeat(batch_size, 1, 1)
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        outputs = model(batch_positions.reshape(-1, 3), batch_meshes)
        
        # è®¡ç®—æŸå¤±
        # 1. é‡å»ºæŸå¤±
        if 'mesh' in outputs:
            recon_loss = torch.nn.functional.mse_loss(outputs['mesh'], batch_meshes)
        else:
            recon_loss = 0
        
        # 2. é¢œè‰²æŸå¤±ï¼ˆç®€åŒ–ï¼‰
        predicted_colors = outputs['color'].reshape(batch_size, -1, 3).mean(1)
        color_loss = torch.nn.functional.mse_loss(predicted_colors, batch_colors)
        
        # 3. SDFæ­£åˆ™åŒ–
        sdf_loss = torch.mean(torch.abs(outputs['sdf']))
        
        total_loss = color_loss + 0.1 * recon_loss + 0.01 * sdf_loss
        
        # åå‘ä¼ æ’­
        total_loss.backward()
        optimizer.step()
        
        # è®°å½•
        if epoch % 40 == 0:
            with torch.no_grad():
                mse = color_loss.item()
                psnr = -10 * np.log10(mse) if mse > 0 else float('inf')
                
                training_history.append({
                    'epoch': epoch, 'total_loss': total_loss.item(
                    )
                })
                
                print(f"Epoch {epoch:3d}: Total={total_loss.item():.6f}, "
                      f"Color={color_loss.item():.6f}, PSNR={psnr:.2f}dB")
    
    print("âœ… è®­ç»ƒå®Œæˆ!")
    return training_history


def demonstrate_dnmp_nerf():
    """æ¼”ç¤ºDNMP NeRFçš„å®Œæ•´æµç¨‹"""
    print("ğŸŒŸ DNMP NeRF æ¼”ç¤º")
    print("=" * 60)
    
    if not DNMP_NERF_AVAILABLE:
        print("âš ï¸ ä½¿ç”¨æ¨¡æ‹Ÿå®ç°è¿›è¡Œæ¼”ç¤º")
    
    # 1. åˆ›å»ºé…ç½®
    config = MockDNMPNeRFConfig()
    print(f"âš™ï¸  æ¨¡å‹é…ç½®:")
    print(f"   - ç½‘æ ¼åˆ†è¾¨ç‡: {config.mesh_resolution}")
    print(f"   - æ½œåœ¨ç»´åº¦: {config.latent_dim}")
    print(f"   - çº¹ç†ç»´åº¦: {config.texture_dim}")
    print(f"   - ä½¿ç”¨ç½‘æ ¼è‡ªåŠ¨ç¼–ç å™¨: {config.use_mesh_autoencoder}")
    
    # 2. åˆ›å»ºæ•°æ®é›†
    dataset = create_mesh_dataset(num_meshes=50, mesh_resolution=32)
    
    # 3. åˆ›å»ºæ¨¡å‹
    model = MockDNMPNeRF(config)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ§  æ¨¡å‹å‚æ•°æ•°é‡: {total_params:, }")
    
    # 4. è®­ç»ƒæ¨¡å‹
    training_history = train_dnmp_nerf(model, dataset, num_epochs=100)
    
    # 5. æ€§èƒ½ç»Ÿè®¡
    print("\n" + "=" * 60)
    print("ğŸ“Š DNMP NeRFæ€§èƒ½ç»Ÿè®¡:")
    
    if training_history:
        final_metrics = training_history[-1]
        print(f"   - æœ€ç»ˆæ€»æŸå¤±: {final_metrics['total_loss']:.6f}")
        print(f"   - æœ€ç»ˆé¢œè‰²æŸå¤±: {final_metrics['color_loss']:.6f}")
        print(f"   - æœ€ç»ˆPSNR: {final_metrics['psnr']:.2f} dB")
        print(f"   - é‡å»ºæŸå¤±: {final_metrics['recon_loss']:.6f}")
        print(f"   - SDFæŸå¤±: {final_metrics['sdf_loss']:.6f}")
    
    print(f"   - æ€»å‚æ•°é‡: {total_params:, }")
    print(f"   - æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB")
    
    print("\nğŸ‰ DNMP NeRFæ¼”ç¤ºå®Œæˆ!")
    print("\nğŸ“‹ DNMP NeRFç‰¹ç‚¹:")
    print("   âœ… å¯å¾®åˆ†ç½‘æ ¼è¡¨ç¤º")
    print("   âœ… ç½‘æ ¼è‡ªåŠ¨ç¼–ç å™¨")
    print("   âœ… SDFå‡ ä½•å»ºæ¨¡")
    print("   âœ… çº¹ç†ä¸å‡ ä½•è”åˆä¼˜åŒ–")
    print("   âœ… é«˜æ•ˆå…‰æ …åŒ–æ¸²æŸ“")
    print("   âœ… æ˜¾å¼å‡ ä½•æ§åˆ¶")
    
    return model, training_history


if __name__ == '__main__':
    print("å¯åŠ¨DNMP NeRFæ¼”ç¤º...")
    model, history = demonstrate_dnmp_nerf()
    print("æ¼”ç¤ºå®Œæˆ!") 