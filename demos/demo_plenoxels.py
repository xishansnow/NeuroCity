#!/usr/bin/env python3
"""
Plenoxels æ¼”ç¤ºè„šæœ¬

å±•ç¤ºPlenoxelsçš„ç¨€ç–ä½“ç´ æ¸²æŸ“æŠ€æœ¯ï¼ŒåŒ…æ‹¬ï¼š
- ç¨€ç–ä½“ç´ ç½‘æ ¼
- çƒè°å‡½æ•°å»ºæ¨¡
- å¿«é€Ÿæ¸²æŸ“
- NeuralVDBé›†æˆ
"""

import sys
import os
import torch
import numpy as np
from typing import Dict, List, Optional, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from src.nerfs.plenoxels.core import Plenoxels, PlenoxelsConfig
    from src.nerfs.plenoxels.trainer import PlenoxelsTrainer
    PLENOXELS_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Plenoxelsæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    PLENOXELS_AVAILABLE = False


class MockPlenoxelsConfig:
    """æ¨¡æ‹ŸPlenoxelsé…ç½®"""
    def __init__(self):
        self.grid_resolution = [128, 128, 128]
        self.sh_degree = 2
        self.density_threshold = 0.01
        self.scene_bounds = (-2.0, -2.0, -2.0, 2.0, 2.0, 2.0)
        self.voxel_size = 0.03125  # 4.0 / 128
        self.use_sparse_grid = True
        self.pruning_threshold = 1e-4


class MockPlenoxels(torch.nn.Module):
    """æ¨¡æ‹ŸPlenoxelsæ¨¡å‹"""
    
    def __init__(self, config):
        super().__init__()
        self.config = config
        
        # ç¨€ç–ä½“ç´ ç½‘æ ¼
        total_voxels = np.prod(config.grid_resolution)
        
        # å¯†åº¦ç½‘æ ¼
        self.density_grid = torch.nn.Parameter(
            torch.randn(total_voxels) * 0.1
        )
        
        # çƒè°ç³»æ•°ç½‘æ ¼ (SHåº¦æ•°å†³å®šç³»æ•°æ•°é‡)
        sh_coeffs = (config.sh_degree + 1) ** 2
        self.sh_grid = torch.nn.Parameter(
            torch.randn(total_voxels, sh_coeffs, 3) * 0.1
        )
        
        # æ´»è·ƒä½“ç´ æ©ç 
        self.register_buffer('active_mask', torch.ones(total_voxels, dtype=torch.bool))
        
    def get_voxel_indices(self, positions: torch.Tensor) -> torch.Tensor:
        """å°†ä¸–ç•Œåæ ‡è½¬æ¢ä¸ºä½“ç´ ç´¢å¼•"""
        # æ ‡å‡†åŒ–åˆ°[0, 1]èŒƒå›´
        bounds = torch.tensor(self.config.scene_bounds)
        min_bounds = bounds[:3]
        max_bounds = bounds[3:]
        
        normalized = (positions - min_bounds) / (max_bounds - min_bounds)
        normalized = torch.clamp(normalized, 0, 1)
        
        # è½¬æ¢ä¸ºä½“ç´ ç´¢å¼•
        grid_coords = normalized * torch.tensor(self.config.grid_resolution, dtype=torch.float32)
        grid_coords = torch.clamp(grid_coords, 0, torch.tensor(self.config.grid_resolution, dtype=torch.float32) - 1)
        
        # çº¿æ€§ç´¢å¼•
        indices = (grid_coords[..., 0] * self.config.grid_resolution[1] * self.config.grid_resolution[2] + 
                   grid_coords[..., 1] * self.config.grid_resolution[2] + 
                   grid_coords[..., 2]).long()
        
        return indices
    
    def spherical_harmonics(self, directions: torch.Tensor, degree: int = 2) -> torch.Tensor:
        """è®¡ç®—çƒè°å‡½æ•°åŸº"""
        x, y, z = directions[..., 0], directions[..., 1], directions[..., 2]
        
        # 0é˜¶
        sh_0_0 = torch.ones_like(x) * 0.28209479177387814
        
        # 1é˜¶
        sh_1_n1 = 0.4886025119029199 * y
        sh_1_0 = 0.4886025119029199 * z
        sh_1_p1 = 0.4886025119029199 * x
        
        sh_coeffs = [sh_0_0, sh_1_n1, sh_1_0, sh_1_p1]
        
        if degree >= 2:
            # 2é˜¶
            sh_2_n2 = 1.0925484305920792 * x * y
            sh_2_n1 = 1.0925484305920792 * y * z
            sh_2_0 = 0.31539156525252005 * (3 * z * z - 1)
            sh_2_p1 = 1.0925484305920792 * x * z
            sh_2_p2 = 0.5462742152960396 * (x * x - y * y)
            
            sh_coeffs.extend([sh_2_n2, sh_2_n1, sh_2_0, sh_2_p1, sh_2_p2])
        
        return torch.stack(sh_coeffs, dim=-1)
    
    def forward(self, positions: torch.Tensor, directions: torch.Tensor) -> Dict[str, torch.Tensor]:
        """å‰å‘ä¼ æ’­"""
        batch_size = positions.shape[0]
        
        # è·å–ä½“ç´ ç´¢å¼•
        voxel_indices = self.get_voxel_indices(positions)
        
        # è·å–å¯†åº¦
        densities = torch.relu(self.density_grid[voxel_indices])
        
        # è®¡ç®—çƒè°åŸº
        sh_basis = self.spherical_harmonics(directions, self.config.sh_degree)
        
        # è·å–çƒè°ç³»æ•°å¹¶è®¡ç®—é¢œè‰²
        sh_coeffs = self.sh_grid[voxel_indices]  # [batch_size, sh_coeffs, 3]
        
        # è®¡ç®—RGBé¢œè‰²
        colors = torch.sum(sh_coeffs * sh_basis.unsqueeze(-1), dim=-2)
        colors = torch.sigmoid(colors)
        
        return {
            'density': densities,
            'color': colors,
            'active_voxels': self.active_mask.sum().item()
        }
    
    def prune_voxels(self, threshold: float = 1e-4):
        """ä¿®å‰ªå¯†åº¦ä½çš„ä½“ç´ """
        with torch.no_grad():
            # æ ‡è®°æ´»è·ƒä½“ç´ 
            active = torch.abs(self.density_grid) > threshold
            self.active_mask &= active
            
            # å°†éæ´»è·ƒä½“ç´ çš„å‚æ•°è®¾ä¸ºé›¶
            self.density_grid.data[~self.active_mask] = 0
            self.sh_grid.data[~self.active_mask] = 0


def create_voxel_dataset(num_views: int = 80, grid_resolution: int = 64) -> Dict[str, torch.Tensor]:
    """åˆ›å»ºä½“ç´ æ•°æ®é›†"""
    print(f"ğŸ“Š åˆ›å»ºä½“ç´ æ•°æ®é›†: {num_views}ä¸ªè§†è§’, ç½‘æ ¼åˆ†è¾¨ç‡{grid_resolution}Â³")
    
    ray_origins = []
    ray_directions = []
    colors = []
    
    for i in range(num_views):
        # ç›¸æœºä½ç½®
        theta = 2 * np.pi * i / num_views
        phi = 0.3 * np.sin(3 * theta)
        
        cam_pos = torch.tensor([
            2.5 * np.cos(theta),
            2.5 * np.sin(theta),
            1.5 + phi
        ])
        
        # ç”Ÿæˆå…‰çº¿ï¼ˆç®€åŒ–ç‰ˆï¼‰
        for _ in range(100):
            # éšæœºæ–¹å‘
            target = torch.randn(3) * 0.5
            ray_dir = target - cam_pos
            ray_dir = ray_dir / torch.norm(ray_dir)
            
            # åŸºäºä½“ç´ ä½ç½®çš„é¢œè‰²
            distance = torch.norm(cam_pos)
            angle_factor = theta / (2 * np.pi)
            color = torch.sigmoid(torch.tensor([
                0.7 + 0.3 * ray_dir[0] + 0.1 * angle_factor,
                0.5 + 0.4 * ray_dir[1] + 0.1 * np.sin(distance),
                0.3 + 0.5 * ray_dir[2] + 0.1 * np.cos(distance)
            ]))
            
            ray_origins.append(cam_pos)
            ray_directions.append(ray_dir)
            colors.append(color)
    
    return {
        'ray_origins': torch.stack(ray_origins),
        'ray_directions': torch.stack(ray_directions),
        'colors': torch.stack(colors)
    }


def train_plenoxels(model: MockPlenoxels,
                   dataset: Dict[str, torch.Tensor],
                   num_epochs: int = 200) -> List[Dict]:
    """è®­ç»ƒPlenoxelsæ¨¡å‹"""
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒPlenoxelsæ¨¡å‹")
    print(f"ğŸ“ˆ è®­ç»ƒæ•°æ®: {len(dataset['ray_origins'])} æ¡å…‰çº¿")
    print(f"ğŸ§Š ä½“ç´ ç½‘æ ¼: {model.config.grid_resolution}")
    print(f"ğŸ”„ è®­ç»ƒè½®æ¬¡: {num_epochs}")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    model = model.to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)
    
    ray_origins = dataset['ray_origins'].to(device)
    ray_directions = dataset['ray_directions'].to(device)
    colors = dataset['colors'].to(device)
    
    training_history = []
    
    for epoch in range(num_epochs):
        # éšæœºé‡‡æ ·
        batch_size = 1024
        indices = torch.randperm(len(ray_origins))[:batch_size]
        
        batch_origins = ray_origins[indices]
        batch_directions = ray_directions[indices]
        batch_colors = colors[indices]
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        outputs = model(batch_origins, batch_directions)
        
        # è®¡ç®—æŸå¤±
        color_loss = torch.nn.functional.mse_loss(outputs['color'], batch_colors)
        
        # ç¨€ç–æ­£åˆ™åŒ–
        sparsity_loss = torch.mean(torch.abs(model.density_grid))
        
        total_loss = color_loss + 0.01 * sparsity_loss
        
        # åå‘ä¼ æ’­
        total_loss.backward()
        optimizer.step()
        
        # å®šæœŸä¿®å‰ª
        if epoch % 50 == 0 and epoch > 0:
            model.prune_voxels(model.config.pruning_threshold)
        
        # è®°å½•
        if epoch % 40 == 0:
            with torch.no_grad():
                mse = color_loss.item()
                psnr = -10 * np.log10(mse) if mse > 0 else float('inf')
                
                training_history.append({
                    'epoch': epoch,
                    'color_loss': color_loss.item(),
                    'sparsity_loss': sparsity_loss.item(),
                    'total_loss': total_loss.item(),
                    'psnr': psnr,
                    'active_voxels': outputs['active_voxels']
                })
                
                print(f"Epoch {epoch:3d}: Color={color_loss.item():.6f}, "
                      f"Sparse={sparsity_loss.item():.6f}, PSNR={psnr:.2f}dB, "
                      f"Active={outputs['active_voxels']}")
    
    print("âœ… è®­ç»ƒå®Œæˆ!")
    return training_history


def demonstrate_plenoxels():
    """æ¼”ç¤ºPlenoxelsçš„å®Œæ•´æµç¨‹"""
    print("ğŸŒŸ Plenoxels æ¼”ç¤º")
    print("=" * 60)
    
    if not PLENOXELS_AVAILABLE:
        print("âš ï¸ ä½¿ç”¨æ¨¡æ‹Ÿå®ç°è¿›è¡Œæ¼”ç¤º")
    
    # 1. åˆ›å»ºé…ç½®
    config = MockPlenoxelsConfig()
    print(f"âš™ï¸  æ¨¡å‹é…ç½®:")
    print(f"   - ç½‘æ ¼åˆ†è¾¨ç‡: {config.grid_resolution}")
    print(f"   - çƒè°é˜¶æ•°: {config.sh_degree}")
    print(f"   - ä½“ç´ å¤§å°: {config.voxel_size}")
    print(f"   - å¯†åº¦é˜ˆå€¼: {config.density_threshold}")
    print(f"   - ä½¿ç”¨ç¨€ç–ç½‘æ ¼: {config.use_sparse_grid}")
    
    # 2. åˆ›å»ºæ•°æ®é›†
    dataset = create_voxel_dataset(num_views=40, grid_resolution=64)
    
    # 3. åˆ›å»ºæ¨¡å‹
    model = MockPlenoxels(config)
    total_params = sum(p.numel() for p in model.parameters())
    total_voxels = np.prod(config.grid_resolution)
    print(f"ğŸ§  æ¨¡å‹å‚æ•°æ•°é‡: {total_params:,}")
    print(f"ğŸ§Š æ€»ä½“ç´ æ•°é‡: {total_voxels:,}")
    
    # 4. è®­ç»ƒæ¨¡å‹
    training_history = train_plenoxels(model, dataset, num_epochs=120)
    
    # 5. æ€§èƒ½ç»Ÿè®¡
    print("\n" + "=" * 60)
    print("ğŸ“Š Plenoxelsæ€§èƒ½ç»Ÿè®¡:")
    
    if training_history:
        final_metrics = training_history[-1]
        print(f"   - æœ€ç»ˆé¢œè‰²æŸå¤±: {final_metrics['color_loss']:.6f}")
        print(f"   - æœ€ç»ˆç¨€ç–æŸå¤±: {final_metrics['sparsity_loss']:.6f}")
        print(f"   - æœ€ç»ˆPSNR: {final_metrics['psnr']:.2f} dB")
        print(f"   - æ´»è·ƒä½“ç´ æ•°: {final_metrics['active_voxels']:,}")
        print(f"   - ä½“ç´ ç¨€ç–ç‡: {(1 - final_metrics['active_voxels'] / total_voxels) * 100:.1f}%")
    
    print(f"   - æ€»å‚æ•°é‡: {total_params:,}")
    print(f"   - æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB")
    print(f"   - å†…å­˜æ•ˆç‡: {total_params / total_voxels:.2f} å‚æ•°/ä½“ç´ ")
    
    print("\nğŸ‰ Plenoxelsæ¼”ç¤ºå®Œæˆ!")
    print("\nğŸ“‹ Plenoxelsç‰¹ç‚¹:")
    print("   âœ… ç¨€ç–ä½“ç´ ç½‘æ ¼è¡¨ç¤º")
    print("   âœ… çƒè°å‡½æ•°é¢œè‰²å»ºæ¨¡")
    print("   âœ… å¿«é€Ÿä½“ç§¯æ¸²æŸ“")
    print("   âœ… å†…å­˜é«˜æ•ˆå­˜å‚¨")
    print("   âœ… è‡ªé€‚åº”ä½“ç´ ä¿®å‰ª")
    print("   âœ… å®æ—¶æ¸²æŸ“èƒ½åŠ›")
    print("   âœ… NeuralVDBé›†æˆ")
    
    return model, training_history


if __name__ == '__main__':
    print("å¯åŠ¨Plenoxelsæ¼”ç¤º...")
    model, history = demonstrate_plenoxels()
    print("æ¼”ç¤ºå®Œæˆ!") 