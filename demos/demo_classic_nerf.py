#!/usr/bin/env python3
"""
Classic NeRF æ¼”ç¤ºè„šæœ¬

å±•ç¤ºç»å…¸Neural Radiance Fieldsçš„åŸºæœ¬ä½¿ç”¨æ–¹æ³•ï¼ŒåŒ…æ‹¬ï¼š
- åŸºç¡€è®­ç»ƒæµç¨‹
- æ–°è§†è§’åˆæˆ
- æ¸²æŸ“è´¨é‡è¯„ä¼°
- æ¨¡å‹ä¿å­˜ä¸åŠ è½½
"""

import sys
import os
import torch
import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, List, Optional, Tuple

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from src.nerfs.classic_nerf.core import ClassicNeRF, ClassicNeRFConfig
    from src.nerfs.classic_nerf.dataset import ClassicNeRFDataset
    from src.nerfs.classic_nerf.trainer import ClassicNeRFTrainer
    CLASSIC_NERF_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Classic NeRFæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    CLASSIC_NERF_AVAILABLE = False


class MockClassicNeRFConfig:
    """æ¨¡æ‹ŸClassic NeRFé…ç½®"""
    def __init__(self):
        self.hidden_dim = 256
        self.num_layers = 8
        self.skip_layers = [4]
        self.use_viewdirs = True
        self.scene_bounds = (-2.0, -2.0, -2.0, 2.0, 2.0, 2.0)
        self.near = 0.1
        self.far = 10.0
        self.num_samples = 64
        self.num_importance_samples = 128
        self.pe_freq_pos = 10
        self.pe_freq_dir = 4


class MockClassicNeRF(torch.nn.Module):
    """æ¨¡æ‹ŸClassic NeRFæ¨¡å‹"""
    
    def __init__(self, config):
        super().__init__()
        self.config = config
        
        # ä½ç½®ç¼–ç MLP
        pos_input_dim = 3 + 3 * 2 * config.pe_freq_pos
        
        # å¯†åº¦ç½‘ç»œ
        density_layers = []
        for i in range(config.num_layers):
            if i == 0:
                density_layers.append(torch.nn.Linear(pos_input_dim, config.hidden_dim))
            elif i in config.skip_layers:
                density_layers.append(
                    torch.nn.Linear,
                )
            else:
                density_layers.append(torch.nn.Linear(config.hidden_dim, config.hidden_dim))
            
            if i < config.num_layers - 1:
                density_layers.append(torch.nn.ReLU())
        
        self.density_net = torch.nn.ModuleList(density_layers)
        
        # é¢œè‰²ç½‘ç»œ
        if config.use_viewdirs:
            dir_input_dim = 3 + 3 * 2 * config.pe_freq_dir
            self.color_net = torch.nn.Sequential(
                torch.nn.Linear(
                    config.hidden_dim + dir_input_dim,
                    config.hidden_dim // 2,
                )
            )
        else:
            self.color_net = torch.nn.Sequential(
                torch.nn.Linear(config.hidden_dim, 3), torch.nn.Sigmoid()
            )
        
        # å¯†åº¦è¾“å‡ºå±‚
        self.density_head = torch.nn.Sequential(
            torch.nn.Linear(config.hidden_dim, 1), torch.nn.ReLU()
        )
    
    def positional_encoding(self, x: torch.Tensor, num_freqs: int) -> torch.Tensor:
        """ä½ç½®ç¼–ç """
        encoded = [x]
        for i in range(num_freqs):
            for fn in [torch.sin, torch.cos]:
                encoded.append(fn(2.**i * x))
        return torch.cat(encoded, dim=-1)
    
    def forward(
        self,
        positions: torch.Tensor,
        directions: Optional[torch.Tensor] = None,
    )
        """å‰å‘ä¼ æ’­"""
        # ä½ç½®ç¼–ç 
        pos_encoded = self.positional_encoding(positions, self.config.pe_freq_pos)
        
        # å¯†åº¦ç½‘ç»œå‰å‘ä¼ æ’­
        x = pos_encoded
        for i, layer in enumerate(self.density_net):
            if i in self.config.skip_layers and i > 0:
                x = torch.cat([x, pos_encoded], dim=-1)
            x = layer(x)
        
        # å¯†åº¦è¾“å‡º
        density = self.density_head(x)
        
        # é¢œè‰²ç½‘ç»œ
        if self.config.use_viewdirs and directions is not None:
            dir_encoded = self.positional_encoding(directions, self.config.pe_freq_dir)
            color_input = torch.cat([x, dir_encoded], dim=-1)
        else:
            color_input = x
        
        color = self.color_net(color_input)
        
        return {
            'density': density.squeeze(-1), 'color': color
        }


def create_synthetic_dataset(
    num_views: int = 100,
    image_size: int = 64,
)
    """åˆ›å»ºåˆæˆæ•°æ®é›†ç”¨äºæ¼”ç¤º"""
    print(f"ğŸ“Š åˆ›å»ºåˆæˆæ•°æ®é›†: {num_views}ä¸ªè§†è§’, å›¾åƒå¤§å°{image_size}x{image_size}")
    
    # ç”Ÿæˆç›¸æœºä½ç½®ï¼ˆå›´ç»•åŸç‚¹çš„çƒé¢ï¼‰
    angles = torch.linspace(0, 2*np.pi, num_views)
    elevations = torch.linspace(-np.pi/6, np.pi/6, num_views)
    
    ray_origins = []
    ray_directions = []
    colors = []
    
    for i in range(num_views):
        # ç›¸æœºä½ç½®
        radius = 3.0
        theta = angles[i]
        phi = elevations[i % len(elevations)]
        
        cam_pos = torch.tensor([
            radius * torch.cos(
                phi,
            )
        ])
        
        # ç”Ÿæˆå…‰çº¿
        for y in range(image_size):
            for x in range(image_size):
                # åƒç´ åæ ‡è½¬æ¢ä¸ºä¸–ç•Œåæ ‡
                u = (x - image_size/2) / (image_size/2)
                v = (y - image_size/2) / (image_size/2)
                
                # ç®€åŒ–çš„å…‰çº¿æ–¹å‘ï¼ˆå‡è®¾æœå‘åŸç‚¹ï¼‰
                ray_dir = torch.tensor([u, v, -1.0])
                ray_dir = ray_dir / torch.norm(ray_dir)
                
                # ç®€å•çš„é¢œè‰²å‡½æ•°ï¼ˆåŸºäºä½ç½®å’Œæ–¹å‘ï¼‰
                color = torch.sigmoid(cam_pos + ray_dir)
                
                ray_origins.append(cam_pos)
                ray_directions.append(ray_dir)
                colors.append(color)
    
    return (
        torch.stack(ray_origins), torch.stack(ray_directions), torch.stack(colors)
    )


def train_classic_nerf(
    config: MockClassicNeRFConfig,
    ray_origins: torch.Tensor,
    ray_directions: torch.Tensor,
    target_colors: torch.Tensor,
    num_epochs: int = 100,
)
    """è®­ç»ƒClassic NeRFæ¨¡å‹"""
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒClassic NeRFæ¨¡å‹")
    print(f"ğŸ“ˆ è®­ç»ƒæ•°æ®: {len(ray_origins)} æ¡å…‰çº¿")
    print(f"ğŸ”„ è®­ç»ƒè½®æ¬¡: {num_epochs}")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ¨¡å‹
    model = MockClassicNeRF(config).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)
    
    # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
    ray_origins = ray_origins.to(device)
    ray_directions = ray_directions.to(device)
    target_colors = target_colors.to(device)
    
    # è®­ç»ƒå¾ªç¯
    model.train()
    for epoch in range(num_epochs):
        # éšæœºé‡‡æ ·å…‰çº¿
        batch_size = 1024
        indices = torch.randperm(len(ray_origins))[:batch_size]
        
        batch_origins = ray_origins[indices]
        batch_directions = ray_directions[indices]
        batch_colors = target_colors[indices]
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        outputs = model(batch_origins, batch_directions)
        
        # è®¡ç®—æŸå¤±
        color_loss = torch.nn.functional.mse_loss(outputs['color'], batch_colors)
        
        # åå‘ä¼ æ’­
        color_loss.backward()
        optimizer.step()
        
        # è®°å½•è¿›åº¦
        if epoch % 20 == 0:
            with torch.no_grad():
                # è®¡ç®—PSNR
                mse = color_loss.item()
                psnr = -10 * np.log10(mse) if mse > 0 else float('inf')
                print(f"Epoch {epoch:3d}: Loss={color_loss.item():.6f}, PSNR={psnr:.2f}dB")
    
    print("âœ… è®­ç»ƒå®Œæˆ!")
    return model


def render_novel_views(
    model: MockClassicNeRF,
    config: MockClassicNeRFConfig,
    num_views: int = 8,
    image_size: int = 64,
)
    """æ¸²æŸ“æ–°è§†è§’"""
    print(f"ğŸ¬ æ¸²æŸ“æ–°è§†è§’: {num_views}ä¸ªè§†è§’")
    
    device = next(model.parameters()).device
    model.eval()
    
    rendered_images = []
    
    with torch.no_grad():
        for i in range(num_views):
            # æ–°çš„ç›¸æœºä½ç½®
            theta = 2 * np.pi * i / num_views
            cam_pos = torch.tensor([
                2.5 * np.cos(theta), 2.5 * np.sin(theta), 1.0
            ]).to(device)
            
            # æ¸²æŸ“å›¾åƒ
            image = torch.zeros(image_size, image_size, 3)
            
            for y in range(image_size):
                for x in range(image_size):
                    u = (x - image_size/2) / (image_size/2)
                    v = (y - image_size/2) / (image_size/2)
                    
                    ray_dir = torch.tensor([u, v, -1.0]).to(device)
                    ray_dir = ray_dir / torch.norm(ray_dir)
                    
                    # ç®€åŒ–æ¸²æŸ“ï¼ˆä¸è¿›è¡Œä½“ç§¯æ¸²æŸ“ï¼Œç›´æ¥ä½¿ç”¨æ¨¡å‹è¾“å‡ºï¼‰
                    output = model(cam_pos.unsqueeze(0), ray_dir.unsqueeze(0))
                    image[y, x] = output['color'][0].cpu()
            
            rendered_images.append(image)
    
    return rendered_images


def visualize_results(rendered_images: list[torch.Tensor], save_path: str = "demo_outputs"):
    """å¯è§†åŒ–æ¸²æŸ“ç»“æœ"""
    print(f"ğŸ“Š å¯è§†åŒ–æ¸²æŸ“ç»“æœ")
    
    os.makedirs(save_path, exist_ok=True)
    
    # åˆ›å»ºå¯¹æ¯”å›¾
    num_images = len(rendered_images)
    cols = min(4, num_images)
    rows = (num_images + cols - 1) // cols
    
    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))
    if rows == 1:
        axes = axes.reshape(1, -1)
    
    for i, image in enumerate(rendered_images):
        row = i // cols
        col = i % cols
        
        axes[row, col].imshow(image.numpy())
        axes[row, col].set_title(f'è§†è§’ {i+1}')
        axes[row, col].axis('off')
    
    # éšè—å¤šä½™çš„å­å›¾
    for i in range(num_images, rows * cols):
        row = i // cols
        col = i % cols
        axes[row, col].axis('off')
    
    plt.tight_layout()
    plt.savefig(f"{save_path}/classic_nerf_novel_views.png", dpi=150, bbox_inches='tight')
    plt.close()
    
    # ä¿å­˜å•ä¸ªå›¾åƒ
    for i, image in enumerate(rendered_images):
        plt.figure(figsize=(4, 4))
        plt.imshow(image.numpy())
        plt.title(f'Classic NeRF æ–°è§†è§’ {i+1}')
        plt.axis('off')
        plt.savefig(f"{save_path}/classic_nerf_view_{i+1:02d}.png", dpi=150, bbox_inches='tight')
        plt.close()
    
    print(f"ğŸ’¾ ç»“æœä¿å­˜åˆ°: {save_path}/")


def demonstrate_classic_nerf():
    """æ¼”ç¤ºClassic NeRFçš„å®Œæ•´æµç¨‹"""
    print("ğŸŒŸ Classic NeRF æ¼”ç¤º")
    print("=" * 60)
    
    if not CLASSIC_NERF_AVAILABLE:
        print("âš ï¸ ä½¿ç”¨æ¨¡æ‹Ÿå®ç°è¿›è¡Œæ¼”ç¤º")
    
    # 1. åˆ›å»ºé…ç½®
    config = MockClassicNeRFConfig()
    print(f"âš™ï¸  æ¨¡å‹é…ç½®:")
    print(f"   - éšè—å±‚ç»´åº¦: {config.hidden_dim}")
    print(f"   - ç½‘ç»œå±‚æ•°: {config.num_layers}")
    print(f"   - ä½¿ç”¨è§†è§’æ–¹å‘: {config.use_viewdirs}")
    print(f"   - é‡‡æ ·ç‚¹æ•°: {config.num_samples}")
    
    # 2. åˆ›å»ºæ•°æ®é›†
    ray_origins, ray_directions, target_colors = create_synthetic_dataset(
        num_views=20, image_size=32
    )
    
    # 3. è®­ç»ƒæ¨¡å‹
    model = train_classic_nerf(
        config, ray_origins, ray_directions, target_colors, num_epochs=100
    )
    
    # 4. æ¸²æŸ“æ–°è§†è§’
    rendered_images = render_novel_views(model, config, num_views=6, image_size=32)
    
    # 5. å¯è§†åŒ–ç»“æœ
    visualize_results(rendered_images)
    
    # 6. æ¨¡å‹ä¿¡æ¯
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æ¨¡å‹ç»Ÿè®¡:")
    print(f"   - æ€»å‚æ•°é‡: {total_params:, }")
    print(f"   - å¯è®­ç»ƒå‚æ•°: {trainable_params:, }")
    print(f"   - æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB")
    
    print("\nğŸ‰ Classic NeRFæ¼”ç¤ºå®Œæˆ!")
    print("\nğŸ“‹ Classic NeRFç‰¹ç‚¹:")
    print("   âœ… éšå¼åœºæ™¯è¡¨ç¤º")
    print("   âœ… è¿ç»­çš„ä½“ç§¯å¯†åº¦å’Œé¢œè‰²")
    print("   âœ… è§†è§’ç›¸å…³çš„é¢œè‰²æ¸²æŸ“")
    print("   âœ… é«˜è´¨é‡çš„æ–°è§†è§’åˆæˆ")
    print("   âœ… ç«¯åˆ°ç«¯å¯å¾®åˆ†æ¸²æŸ“")
    
    return model, rendered_images


if __name__ == '__main__':
    print("å¯åŠ¨Classic NeRFæ¼”ç¤º...")
    model, images = demonstrate_classic_nerf()
    print("æ¼”ç¤ºå®Œæˆ!") 