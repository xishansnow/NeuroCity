from typing import Optional
#!/usr/bin/env python3
"""
Nerfacto æ¼”ç¤ºè„šæœ¬

å±•ç¤ºNerfactoçš„å®ç”¨åŒ–NeRFå®ç°ï¼ŒåŒ…æ‹¬ï¼š
- å¿«é€Ÿæ”¶æ•›è®­ç»ƒ
- é«˜è´¨é‡æ¸²æŸ“
- ç›¸æœºå‚æ•°ä¼˜åŒ–
- å®ç”¨å·¥å…·é›†æˆ
"""

import sys
import os
import torch
import numpy as np
import matplotlib.pyplot as plt

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from src.nerfs.nerfacto.core import Nerfacto, NeRFactoConfig
    from src.nerfs.nerfacto.trainer import NerfactoTrainer
    NERFACTO_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ Nerfactoæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    NERFACTO_AVAILABLE = False

class MockNerfactoConfig:
    """æ¨¡æ‹ŸNerfactoé…ç½®"""
    def __init__(self):
        self.hidden_dim = 256
        self.num_layers = 8
        self.skip_layers = [4]
        self.geo_feat_dim = 256
        self.num_levels = 16
        self.max_res = 2048
        self.base_res = 16
        self.log2_hashmap_size = 19
        self.features_per_level = 2
        self.scene_bounds = (-2.0, -2.0, -2.0, 2.0, 2.0, 2.0)
        self.near = 0.05
        self.far = 1000.0
        self.num_samples = 64
        self.num_importance_samples = 128

class MockNerfacto(torch.nn.Module):
    """æ¨¡æ‹ŸNerfactoæ¨¡å‹"""
    
    def __init__(self, config):
        super().__init__()
        self.config = config
        
        # å“ˆå¸Œç¼–ç ç½‘ç»œï¼ˆç®€åŒ–ï¼‰
        self.hash_encoding = torch.nn.Sequential(
            torch.nn.Linear(3, 64), torch.nn.ReLU(), torch.nn.Linear(64, config.geo_feat_dim)
        )
        
        # å‡ ä½•ç½‘ç»œ
        geo_layers = []
        in_dim = config.geo_feat_dim
        for i in range(config.num_layers):
            if i in config.skip_layers:
                geo_layers.append(torch.nn.Linear(in_dim + config.geo_feat_dim, config.hidden_dim))
            else:
                geo_layers.append(torch.nn.Linear(in_dim, config.hidden_dim))
            
            if i < config.num_layers - 1:
                geo_layers.append(torch.nn.ReLU())
            in_dim = config.hidden_dim
        
        self.geometry_network = torch.nn.ModuleList(geo_layers)
        
        # å¯†åº¦å¤´
        self.density_head = torch.nn.Sequential(
            torch.nn.Linear(config.hidden_dim, 1), torch.nn.Softplus()
        )
        
        # é¢œè‰²ç½‘ç»œ
        self.color_network = torch.nn.Sequential(
            torch.nn.Linear(
                config.hidden_dim + 27,
                config.hidden_dim // 2,
            )
            torch.nn.ReLU(), torch.nn.Linear(config.hidden_dim // 2, 3), torch.nn.Sigmoid()
        )
    
    def hash_encode(self, positions: torch.Tensor) -> torch.Tensor:
        """å“ˆå¸Œç¼–ç ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        return self.hash_encoding(positions)
    
    def spherical_harmonics_encoding(self, directions: torch.Tensor) -> torch.Tensor:
        """çƒè°ç¼–ç ï¼ˆç®€åŒ–ï¼‰"""
        # ç®€åŒ–çš„æ–¹å‘ç¼–ç 
        x, y, z = directions[..., 0], directions[..., 1], directions[..., 2]
        
        # ä¸€é˜¶çƒè°å‡½æ•°
        sh_0 = torch.ones_like(x) * 0.28209479177  # Y_0^0
        sh_1 = 0.48860251190 * y                    # Y_1^{-1}
        sh_2 = 0.48860251190 * z                    # Y_1^0
        sh_3 = 0.48860251190 * x                    # Y_1^1
        
        # äºŒé˜¶çƒè°å‡½æ•°ï¼ˆéƒ¨åˆ†ï¼‰
        sh_4 = 1.09254843059 * x * y                # Y_2^{-2}
        sh_5 = 1.09254843059 * y * z                # Y_2^{-1}
        sh_6 = 0.31539156525 * (3*z*z - 1)          # Y_2^0
        sh_7 = 1.09254843059 * x * z                # Y_2^1
        sh_8 = 0.54627421529 * (x*x - y*y)          # Y_2^2
        
        return torch.stack([
            sh_0, sh_1, sh_2, sh_3, sh_4, sh_5, sh_6, sh_7, sh_8, # æ·»åŠ æ›´å¤šé¡¹ä»¥è¾¾åˆ°27ç»´
            x*x, y*y, z*z, x*y, x*z, y*z, x*x*x, y*y*y, z*z*z, x*x*y, x*x*z, y*y*x, y*y*z, z*z*x, z*z*y, x*y*z, x*x*y*y, x*x*z*z, y*y*z*z
        ], dim=-1)
    
    def forward(self, positions: torch.Tensor, directions: torch.Tensor) -> dict[str, torch.Tensor]:
        """å‰å‘ä¼ æ’­"""
        # å“ˆå¸Œç¼–ç 
        geo_features = self.hash_encode(positions)
        
        # å‡ ä½•ç½‘ç»œå‰å‘ä¼ æ’­
        x = geo_features
        for i, layer in enumerate(self.geometry_network):
            if i in self.config.skip_layers and i > 0:
                x = torch.cat([x, geo_features], dim=-1)
            x = layer(x)
        
        # å¯†åº¦
        density = self.density_head(x)
        
        # æ–¹å‘ç¼–ç 
        dir_encoded = self.spherical_harmonics_encoding(directions)
        
        # é¢œè‰²ç½‘ç»œ
        color_input = torch.cat([x, dir_encoded], dim=-1)
        color = self.color_network(color_input)
        
        return {
            'density': density.squeeze(-1), 'color': color
        }

def create_realistic_dataset(
    num_views: int = 100,
    image_size: int = 64,
)
    """åˆ›å»ºæ›´çœŸå®çš„æ•°æ®é›†"""
    print(f"ğŸ“Š åˆ›å»ºçœŸå®æ„Ÿæ•°æ®é›†: {num_views}ä¸ªè§†è§’, å›¾åƒå¤§å°{image_size}x{image_size}")
    
    ray_origins = []
    ray_directions = []
    colors = []
    
    for i in range(num_views):
        # ç›¸æœºè½¨è¿¹
        theta = 2 * np.pi * i / num_views
        phi = 0.2 * np.sin(4 * theta)  # é«˜åº¦å˜åŒ–
        
        cam_pos = torch.tensor([
            3.0 * np.cos(theta), 3.0 * np.sin(theta), 2.0 + phi
        ])
        
        # æœå‘åŸç‚¹
        look_at = torch.tensor([0.0, 0.0, 0.0])
        forward = look_at - cam_pos
        forward = forward / torch.norm(forward)
        
        # æ„å»ºç›¸æœºåæ ‡ç³»
        up = torch.tensor([0.0, 0.0, 1.0])
        right = torch.cross(forward, up)
        right = right / torch.norm(right)
        up = torch.cross(right, forward)
        
        # ç”Ÿæˆå…‰çº¿
        for y in range(image_size):
            for x in range(image_size):
                # å½’ä¸€åŒ–åƒç´ åæ ‡
                u = (x + 0.5) / image_size - 0.5
                v = (y + 0.5) / image_size - 0.5
                
                # å…‰çº¿æ–¹å‘
                ray_dir = forward + u * right + v * up
                ray_dir = ray_dir / torch.norm(ray_dir)
                
                # å¤æ‚çš„é¢œè‰²å‡½æ•°
                distance = torch.norm(cam_pos)
                color = torch.sigmoid(torch.tensor([
                    0.8 + 0.2 * ray_dir[0] + 0.1 * np.sin(
                        distance,
                    )
                ]))
                
                ray_origins.append(cam_pos)
                ray_directions.append(ray_dir)
                colors.append(color)
    
    return (
        torch.stack(ray_origins), torch.stack(ray_directions), torch.stack(colors)
    )

def train_nerfacto(
    model: MockNerfacto,
    ray_origins: torch.Tensor,
    ray_directions: torch.Tensor,
    target_colors: torch.Tensor,
    num_epochs: int = 200,
)
    """è®­ç»ƒNerfactoæ¨¡å‹"""
    print(f"ğŸš€ å¼€å§‹è®­ç»ƒNerfactoæ¨¡å‹")
    print(f"ğŸ“ˆ è®­ç»ƒæ•°æ®: {len(ray_origins)} æ¡å…‰çº¿")
    print(f"ğŸ”„ è®­ç»ƒè½®æ¬¡: {num_epochs}")
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    model = model.to(device)
    
    # ä½¿ç”¨AdamWä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-6)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)
    
    ray_origins = ray_origins.to(device)
    ray_directions = ray_directions.to(device)
    target_colors = target_colors.to(device)
    
    training_history = []
    
    for epoch in range(num_epochs):
        # éšæœºé‡‡æ ·
        batch_size = 2048
        indices = torch.randperm(len(ray_origins))[:batch_size]
        
        batch_origins = ray_origins[indices]
        batch_directions = ray_directions[indices]
        batch_colors = target_colors[indices]
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        outputs = model(batch_origins, batch_directions)
        
        # è®¡ç®—æŸå¤±
        color_loss = torch.nn.functional.mse_loss(outputs['color'], batch_colors)
        
        # L1æ­£åˆ™åŒ–
        l1_reg = sum(torch.sum(torch.abs(param)) for param in model.parameters())
        total_loss = color_loss + 1e-6 * l1_reg
        
        # åå‘ä¼ æ’­
        total_loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
        scheduler.step()
        
        # è®°å½•
        if epoch % 40 == 0:
            with torch.no_grad():
                mse = color_loss.item()
                psnr = -10 * np.log10(mse) if mse > 0 else float('inf')
                lr = scheduler.get_last_lr()[0]
                
                training_history.append({
                    'epoch': epoch, 'loss': color_loss.item(
                    )
                })
                
                print(f"Epoch {epoch:3d}: Loss={color_loss.item():.6f}, PSNR={psnr:.2f}dB, "
                      f"LR={lr:.2e}")
    
    print("âœ… è®­ç»ƒå®Œæˆ!")
    return training_history

def demonstrate_nerfacto():
    """æ¼”ç¤ºNerfactoçš„å®Œæ•´æµç¨‹"""
    print("ğŸŒŸ Nerfacto æ¼”ç¤º")
    print("=" * 60)
    
    if not NERFACTO_AVAILABLE:
        print("âš ï¸ ä½¿ç”¨æ¨¡æ‹Ÿå®ç°è¿›è¡Œæ¼”ç¤º")
    
    # 1. åˆ›å»ºé…ç½®
    config = MockNerfactoConfig()
    print(f"âš™ï¸  æ¨¡å‹é…ç½®:")
    print(f"   - éšè—å±‚ç»´åº¦: {config.hidden_dim}")
    print(f"   - å‡ ä½•ç‰¹å¾ç»´åº¦: {config.geo_feat_dim}")
    print(f"   - å“ˆå¸Œç½‘æ ¼å±‚æ•°: {config.num_levels}")
    print(f"   - æœ€å¤§åˆ†è¾¨ç‡: {config.max_res}")
    print(f"   - åŸºç¡€åˆ†è¾¨ç‡: {config.base_res}")
    
    # 2. åˆ›å»ºæ•°æ®é›†
    ray_origins, ray_directions, target_colors = create_realistic_dataset(
        num_views=30, image_size=48
    )
    
    # 3. åˆ›å»ºæ¨¡å‹
    model = MockNerfacto(config)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"ğŸ§  æ¨¡å‹å‚æ•°æ•°é‡: {total_params:, }")
    
    # 4. è®­ç»ƒæ¨¡å‹
    training_history = train_nerfacto(
        model, ray_origins, ray_directions, target_colors, num_epochs=120
    )
    
    # 5. æ€§èƒ½ç»Ÿè®¡
    print("\n" + "=" * 60)
    print("ğŸ“Š Nerfactoæ€§èƒ½ç»Ÿè®¡:")
    
    if training_history:
        final_metrics = training_history[-1]
        print(f"   - æœ€ç»ˆæŸå¤±: {final_metrics['loss']:.6f}")
        print(f"   - æœ€ç»ˆPSNR: {final_metrics['psnr']:.2f} dB")
        print(f"   - æœ€ç»ˆå­¦ä¹ ç‡: {final_metrics['learning_rate']:.2e}")
    
    print(f"   - æ€»å‚æ•°é‡: {total_params:, }")
    print(f"   - æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB")
    
    print("\nğŸ‰ Nerfactoæ¼”ç¤ºå®Œæˆ!")
    print("\nğŸ“‹ Nerfactoç‰¹ç‚¹:")
    print("   âœ… å®ç”¨åŒ–NeRFå®ç°")
    print("   âœ… å¿«é€Ÿæ”¶æ•›è®­ç»ƒ")
    print("   âœ… é«˜è´¨é‡æ¸²æŸ“")
    print("   âœ… å¤šå±‚å“ˆå¸Œç¼–ç ")
    print("   âœ… çƒè°æ–¹å‘ç¼–ç ")
    print("   âœ… ç›¸æœºå‚æ•°ä¼˜åŒ–")
    print("   âœ… å·¥ç¨‹åŒ–è®¾è®¡")
    
    return model, training_history

if __name__ == '__main__':
    print("å¯åŠ¨Nerfactoæ¼”ç¤º...")
    model, history = demonstrate_nerfacto()
    print("æ¼”ç¤ºå®Œæˆ!") 