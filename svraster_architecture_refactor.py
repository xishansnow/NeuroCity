"""
SVRaster æ¶æ„é‡æ„å»ºè®®

è§£å†³å…‰æ …åŒ–æ¸²æŸ“é€»è¾‘åº”è¯¥æ”¾åœ¨ SVRasterRenderer ä¸­çš„é—®é¢˜
"""

from __future__ import annotations

import torch
import torch.nn.functional as F
from typing import Dict, List, Tuple, Optional
from pathlib import Path


class SVRasterRendererRefactored:
    """
    é‡æ„åçš„ SVRaster æ¸²æŸ“å™¨
    
    å°†å…‰æ …åŒ–æ¸²æŸ“é€»è¾‘ä»æ¨¡å‹ä¸­ç§»åˆ°æ¸²æŸ“å™¨ä¸­ï¼Œå®ç°æ›´å¥½çš„èŒè´£åˆ†ç¦»
    """
    
    def __init__(self, config):
        self.config = config
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # æ¨¡å‹åªè´Ÿè´£å­˜å‚¨ä½“ç´ æ•°æ®
        self.model: Optional['SVRasterModel'] = None
        
        # æ¸²æŸ“å™¨è´Ÿè´£å®é™…çš„æ¸²æŸ“é€»è¾‘
        self.volume_renderer = None  # ç”¨äºé«˜è´¨é‡æ¸²æŸ“
        self.rasterizer = None      # ç”¨äºå¿«é€Ÿæ¨ç†
        
    def load_model(self, checkpoint_path: str):
        """åŠ è½½æ¨¡å‹"""
        # åŠ è½½æ¨¡å‹ï¼ˆåªåŒ…å«ä½“ç´ æ•°æ®ï¼Œä¸åŒ…å«æ¸²æŸ“é€»è¾‘ï¼‰
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        self.model = SVRasterModelMinimal(checkpoint['model_config'])
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.eval()
        
        # åˆå§‹åŒ–æ¸²æŸ“å™¨
        from .volume_renderer import VolumeRenderer
        from .true_rasterizer import TrueVoxelRasterizer
        
        self.volume_renderer = VolumeRenderer(self.model.config)
        self.rasterizer = TrueVoxelRasterizer(self.model.config)
        
    def render_single_view(
        self,
        camera_pose: torch.Tensor,
        intrinsics: torch.Tensor,
        mode: str = "rasterization",  # "rasterization" æˆ– "volume"
        image_size: Optional[Tuple[int, int]] = None
    ) -> Dict[str, torch.Tensor]:
        """
        æ¸²æŸ“å•ä¸ªè§†è§’
        
        Args:
            camera_pose: ç›¸æœºä½å§¿çŸ©é˜µ
            intrinsics: ç›¸æœºå†…å‚çŸ©é˜µ
            mode: æ¸²æŸ“æ¨¡å¼ - "rasterization" æˆ– "volume"
            image_size: å›¾åƒå°ºå¯¸
            
        Returns:
            æ¸²æŸ“ç»“æœ
        """
        if self.model is None:
            raise RuntimeError("æ¨¡å‹æœªåŠ è½½")
            
        # è®¾ç½®å›¾åƒå°ºå¯¸
        if image_size is None:
            width, height = self.config.image_width, self.config.image_height
        else:
            width, height = image_size
        
        # è·å–ä½“ç´ æ•°æ®
        voxels = self.model.get_all_voxels()
        
        if mode == "rasterization":
            # ä½¿ç”¨å…‰æ …åŒ–æ¸²æŸ“ - å¿«é€Ÿæ¨ç†
            return self._render_rasterization(voxels, camera_pose, intrinsics, width, height)
        elif mode == "volume":
            # ä½¿ç”¨ä½“ç§¯æ¸²æŸ“ - é«˜è´¨é‡æ¸²æŸ“
            return self._render_volume(voxels, camera_pose, intrinsics, width, height)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¸²æŸ“æ¨¡å¼: {mode}")
    
    def _render_rasterization(
        self,
        voxels: Dict[str, torch.Tensor],
        camera_pose: torch.Tensor,
        intrinsics: torch.Tensor,
        width: int,
        height: int
    ) -> Dict[str, torch.Tensor]:
        """
        å…‰æ …åŒ–æ¸²æŸ“å®ç° - åœ¨æ¸²æŸ“å™¨ä¸­å®ç°ï¼Œä¸åœ¨æ¨¡å‹ä¸­
        """
        # ç›´æ¥ä½¿ç”¨å…‰æ …åŒ–å™¨
        viewport_size = (width, height)
        
        outputs = self.rasterizer(
            voxels,
            camera_pose,
            intrinsics,
            viewport_size,
        )
        
        return outputs
    
    def _render_volume(
        self,
        voxels: Dict[str, torch.Tensor],
        camera_pose: torch.Tensor,
        intrinsics: torch.Tensor,
        width: int,
        height: int
    ) -> Dict[str, torch.Tensor]:
        """
        ä½“ç§¯æ¸²æŸ“å®ç° - é«˜è´¨é‡æ¸²æŸ“
        """
        # ç”Ÿæˆå…‰çº¿
        rays_o, rays_d = self._generate_rays(camera_pose, intrinsics, width, height)
        
        # é‡å¡‘ä¸ºæ‰¹æ¬¡æ ¼å¼
        rays_o = rays_o.reshape(-1, 3)
        rays_d = rays_d.reshape(-1, 3)
        
        # æ‰¹é‡æ¸²æŸ“
        batch_size = self.config.render_batch_size
        rgb_list = []
        depth_list = []
        
        for i in range(0, rays_o.shape[0], batch_size):
            batch_rays_o = rays_o[i:i + batch_size]
            batch_rays_d = rays_d[i:i + batch_size]
            
            # ä½¿ç”¨ä½“ç§¯æ¸²æŸ“å™¨
            outputs = self.volume_renderer(
                voxels,
                batch_rays_o,
                batch_rays_d
            )
            
            rgb_list.append(outputs['rgb'])
            if 'depth' in outputs:
                depth_list.append(outputs['depth'])
        
        # åˆå¹¶ç»“æœ
        rgb = torch.cat(rgb_list, dim=0).reshape(height, width, 3)
        results = {'rgb': rgb}
        
        if depth_list:
            depth = torch.cat(depth_list, dim=0).reshape(height, width)
            results['depth'] = depth
        
        return results
    
    def render_path_comparison(
        self,
        camera_poses: List[torch.Tensor],
        intrinsics: torch.Tensor,
        output_dir: str
    ):
        """
        æ¸²æŸ“è·¯å¾„å¯¹æ¯” - å±•ç¤ºä¸¤ç§æ¸²æŸ“æ¨¡å¼çš„å·®å¼‚
        """
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        for i, pose in enumerate(camera_poses):
            # å…‰æ …åŒ–æ¸²æŸ“
            raster_outputs = self.render_single_view(pose, intrinsics, mode="rasterization")
            # ä½“ç§¯æ¸²æŸ“
            volume_outputs = self.render_single_view(pose, intrinsics, mode="volume")
            
            # ä¿å­˜å¯¹æ¯”å›¾åƒ
            self._save_comparison(raster_outputs, volume_outputs, f"{output_dir}/frame_{i:04d}")
    
    def _generate_rays(self, camera_pose, intrinsics, width, height):
        """ç”Ÿæˆå…‰çº¿ - å…±ç”¨æ–¹æ³•"""
        # ... å®ç°ç»†èŠ‚åŒåŸæ¥çš„æ–¹æ³•
        pass
    
    def _save_comparison(self, raster_outputs, volume_outputs, filename_prefix):
        """ä¿å­˜å¯¹æ¯”å›¾åƒ"""
        import imageio
        
        # å…‰æ …åŒ–ç»“æœ
        raster_rgb = (raster_outputs['rgb'].cpu().numpy() * 255).astype('uint8')
        imageio.imwrite(f"{filename_prefix}_rasterization.png", raster_rgb)
        
        # ä½“ç§¯æ¸²æŸ“ç»“æœ
        volume_rgb = (volume_outputs['rgb'].cpu().numpy() * 255).astype('uint8')
        imageio.imwrite(f"{filename_prefix}_volume.png", volume_rgb)
        
        # å·®å¼‚å›¾
        diff = torch.abs(raster_outputs['rgb'] - volume_outputs['rgb'])
        diff_rgb = (diff.cpu().numpy() * 255).astype('uint8')
        imageio.imwrite(f"{filename_prefix}_difference.png", diff_rgb)


class SVRasterModelMinimal:
    """
    æœ€å°åŒ–çš„ SVRaster æ¨¡å‹
    
    åªè´Ÿè´£å­˜å‚¨å’Œç®¡ç†ä½“ç´ æ•°æ®ï¼Œä¸åŒ…å«æ¸²æŸ“é€»è¾‘
    """
    
    def __init__(self, config):
        self.config = config
        self.voxels = None  # ä½“ç´ æ•°æ®å­˜å‚¨
        
    def get_all_voxels(self) -> Dict[str, torch.Tensor]:
        """è·å–æ‰€æœ‰ä½“ç´ æ•°æ®"""
        return self.voxels.get_all_voxels()
    
    def forward(self, *args, **kwargs):
        """
        ç§»é™¤ forward æ–¹æ³•ä¸­çš„æ¸²æŸ“é€»è¾‘
        æ¨¡å‹åªè´Ÿè´£æ•°æ®å­˜å‚¨ï¼Œä¸è´Ÿè´£æ¸²æŸ“
        """
        raise NotImplementedError(
            "æ¨¡å‹ä¸å†åŒ…å«æ¸²æŸ“é€»è¾‘ï¼Œè¯·ä½¿ç”¨ SVRasterRenderer è¿›è¡Œæ¸²æŸ“"
        )


def architecture_benefits():
    """
    æ–°æ¶æ„çš„ä¼˜åŠ¿
    """
    return """
    ğŸ¯ é‡æ„åçš„æ¶æ„ä¼˜åŠ¿ï¼š

    1. **èŒè´£æ¸…æ™°åˆ†ç¦»**:
       - SVRasterModel: åªè´Ÿè´£ä½“ç´ æ•°æ®å­˜å‚¨å’Œç®¡ç†
       - SVRasterRenderer: è´Ÿè´£æ‰€æœ‰æ¸²æŸ“é€»è¾‘ï¼ˆä½“ç§¯æ¸²æŸ“ + å…‰æ …åŒ–ï¼‰

    2. **çµæ´»çš„æ¸²æŸ“æ¨¡å¼**:
       - å¯ä»¥åœ¨è¿è¡Œæ—¶é€‰æ‹©æ¸²æŸ“æ¨¡å¼
       - ä¾¿äºå¯¹æ¯”ä¸åŒæ¸²æŸ“æ–¹æ³•çš„æ•ˆæœ
       - ä¾¿äºæ€§èƒ½è°ƒä¼˜

    3. **ä»£ç å¤ç”¨æ€§**:
       - æ¸²æŸ“å™¨å¯ä»¥å¤ç”¨äºä¸åŒçš„æ¨¡å‹
       - å‡å°‘ä»£ç é‡å¤
       - æ›´å¥½çš„æµ‹è¯•å’Œç»´æŠ¤

    4. **éƒ¨ç½²å‹å¥½**:
       - ç”Ÿäº§ç¯å¢ƒå¯ä»¥åªåŠ è½½æ¸²æŸ“å™¨
       - æ¨¡å‹æ–‡ä»¶æ›´è½»é‡
       - ä¾¿äºä¼˜åŒ–éƒ¨ç½²

    5. **æ‰©å±•æ€§**:
       - å®¹æ˜“æ·»åŠ æ–°çš„æ¸²æŸ“ç®—æ³•
       - ä¾¿äºé›†æˆ GPU åŠ é€Ÿ
       - æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼

    ğŸ“ ä½¿ç”¨ç¤ºä¾‹ï¼š
    ```python
    # åˆ›å»ºæ¸²æŸ“å™¨
    renderer = SVRasterRendererRefactored(config)
    
    # åŠ è½½æ¨¡å‹
    renderer.load_model("model.pth")
    
    # å¿«é€Ÿæ¨ç†ï¼ˆå…‰æ …åŒ–ï¼‰
    fast_result = renderer.render_single_view(pose, intrinsics, mode="rasterization")
    
    # é«˜è´¨é‡æ¸²æŸ“ï¼ˆä½“ç§¯æ¸²æŸ“ï¼‰
    quality_result = renderer.render_single_view(pose, intrinsics, mode="volume")
    
    # å¯¹æ¯”æ¸²æŸ“
    renderer.render_path_comparison(poses, intrinsics, "comparison_output")
    ```

    ğŸ”„ è¿ç§»æ­¥éª¤ï¼š
    1. å°†å…‰æ …åŒ–é€»è¾‘ä» SVRasterModel.forward() ç§»åˆ° SVRasterRenderer
    2. ç®€åŒ– SVRasterModelï¼Œåªä¿ç•™æ•°æ®ç®¡ç†
    3. åœ¨æ¸²æŸ“å™¨ä¸­å®ç°ä¸åŒçš„æ¸²æŸ“æ¨¡å¼
    4. æ›´æ–°æ‰€æœ‰è°ƒç”¨ä»£ç 
    """


if __name__ == "__main__":
    print(architecture_benefits())
