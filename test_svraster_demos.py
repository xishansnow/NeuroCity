#!/usr/bin/env python3
"""
SVRaster æ¼”ç¤ºè„šæœ¬å¿«é€Ÿæµ‹è¯•

å¿«é€ŸéªŒè¯ä¸¤ä¸ªæ¼”ç¤ºè„šæœ¬çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

from __future__ import annotations

import sys
import torch
import time
from pathlib import Path

# æ·»åŠ è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'demos'))

def test_training_demo():
    """æµ‹è¯•è®­ç»ƒæ¼”ç¤ºçš„æ ¸å¿ƒåŠŸèƒ½"""
    print("=== æµ‹è¯•è®­ç»ƒæ¼”ç¤º ===")
    
    try:
        from demo_svraster_training import SVRasterTrainingDemo
        
        # åˆ›å»ºæ¼”ç¤º
        demo = SVRasterTrainingDemo()
        print(f"âœ… è®­ç»ƒæ¼”ç¤ºåˆ›å»ºæˆåŠŸ (è®¾å¤‡: {demo.device})")
        
        # å¿«é€Ÿè®¾ç½®ï¼ˆä½¿ç”¨æ›´å°çš„é…ç½®ï¼‰
        demo.config.base_resolution = 16  # å‡å°ç½‘æ ¼å°ºå¯¸
        demo.config.image_width = 64
        demo.config.image_height = 48
        
        # è®¾ç½®è®­ç»ƒç»„ä»¶
        demo.setup_training()
        print("âœ… è®­ç»ƒç»„ä»¶è®¾ç½®æˆåŠŸ")
        print(f"   æ¨¡å‹å‚æ•°: {sum(p.numel() for p in demo.model.parameters()):,}")
        
        # æµ‹è¯•å•ä¸ªè®­ç»ƒæ­¥éª¤
        batch_data = demo._get_training_batch(0)
        print("âœ… è®­ç»ƒæ‰¹æ¬¡æ•°æ®ç”ŸæˆæˆåŠŸ")
        print(f"   å…‰çº¿æ•°é‡: {len(batch_data['ray_origins'])}")
        
        # æµ‹è¯•æ¨ç†
        with torch.no_grad():
            outputs = demo.model(
                batch_data['ray_origins'][:100],  # åªæµ‹è¯•100æ¡å…‰çº¿
                batch_data['ray_directions'][:100],
                mode="training"
            )
        
        print("âœ… ä½“ç§¯æ¸²æŸ“æµ‹è¯•æˆåŠŸ")
        print(f"   è¾“å‡ºé”®: {list(outputs.keys())}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒæ¼”ç¤ºæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_rendering_demo():
    """æµ‹è¯•æ¸²æŸ“æ¼”ç¤ºçš„æ ¸å¿ƒåŠŸèƒ½"""
    print("\n=== æµ‹è¯•æ¸²æŸ“æ¼”ç¤º ===")
    
    try:
        from demo_svraster_rendering import SVRasterRenderingDemo
        
        # åˆ›å»ºæ¼”ç¤º
        demo = SVRasterRenderingDemo()
        print(f"âœ… æ¸²æŸ“æ¼”ç¤ºåˆ›å»ºæˆåŠŸ (è®¾å¤‡: {demo.device})")
        
        # å¿«é€Ÿè®¾ç½®ï¼ˆä½¿ç”¨æ›´å°çš„é…ç½®ï¼‰
        demo.model_config.base_resolution = 32  # å‡å°ç½‘æ ¼å°ºå¯¸
        demo.model_config.image_width = 128
        demo.model_config.image_height = 96
        demo.render_config.image_width = 128
        demo.render_config.image_height = 96
        demo.render_config.render_batch_size = 1024
        
        # è®¾ç½®æ¨¡å‹å’Œæ¸²æŸ“å™¨
        demo.setup_model_and_renderers()
        print("âœ… æ¨¡å‹å’Œæ¸²æŸ“å™¨è®¾ç½®æˆåŠŸ")
        print(f"   æ¨¡å‹å‚æ•°: {sum(p.numel() for p in demo.model.parameters()):,}")
        
        # æµ‹è¯•å…‰çº¿ç”Ÿæˆ
        import numpy as np
        camera_pos = np.array([2.0, 0.0, 1.0])
        target = np.array([0.0, 0.0, 0.0])
        camera_forward = target - camera_pos
        camera_forward = camera_forward / np.linalg.norm(camera_forward)
        
        ray_origins, ray_directions = demo.generate_ray_batch(
            camera_pos, camera_forward, subset_ratio=0.1  # åªæµ‹è¯•10%çš„å…‰çº¿
        )
        
        print("âœ… å…‰çº¿ç”Ÿæˆæµ‹è¯•æˆåŠŸ")
        print(f"   å…‰çº¿æ•°é‡: {len(ray_origins)}")
        
        # æµ‹è¯•ä½“ç§¯æ¸²æŸ“
        start_time = time.time()
        with torch.no_grad():
            volume_outputs = demo.model(ray_origins, ray_directions, mode="training")
        volume_time = time.time() - start_time
        
        print("âœ… ä½“ç§¯æ¸²æŸ“æµ‹è¯•æˆåŠŸ")
        print(f"   æ¸²æŸ“æ—¶é—´: {volume_time:.4f}s")
        
        # æµ‹è¯•å…‰æ …åŒ–æ¸²æŸ“
        start_time = time.time()
        with torch.no_grad():
            raster_outputs = demo.model(ray_origins, ray_directions, mode="inference")
        raster_time = time.time() - start_time
        
        print("âœ… å…‰æ …åŒ–æ¸²æŸ“æµ‹è¯•æˆåŠŸ")
        print(f"   æ¸²æŸ“æ—¶é—´: {raster_time:.4f}s")
        
        # è®¡ç®—åŠ é€Ÿæ¯”
        if raster_time > 0:
            speedup = volume_time / raster_time
            print(f"   åŠ é€Ÿæ¯”: {speedup:.2f}x")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¸²æŸ“æ¼”ç¤ºæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª SVRaster æ¼”ç¤ºè„šæœ¬å¿«é€Ÿæµ‹è¯•")
    print("=" * 50)
    
    # æ£€æŸ¥è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æµ‹è¯•è®­ç»ƒæ¼”ç¤º
    training_ok = test_training_demo()
    
    # æµ‹è¯•æ¸²æŸ“æ¼”ç¤º
    rendering_ok = test_rendering_demo()
    
    # æ€»ç»“
    print("\n" + "=" * 50)
    print("æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"{'âœ…' if training_ok else 'âŒ'} è®­ç»ƒæ¼”ç¤º: {'é€šè¿‡' if training_ok else 'å¤±è´¥'}")
    print(f"{'âœ…' if rendering_ok else 'âŒ'} æ¸²æŸ“æ¼”ç¤º: {'é€šè¿‡' if rendering_ok else 'å¤±è´¥'}")
    
    if training_ok and rendering_ok:
        print("\nğŸ‰ æ‰€æœ‰æ¼”ç¤ºè„šæœ¬æµ‹è¯•é€šè¿‡ï¼")
        print("\nå¯ä»¥è¿è¡Œå®Œæ•´æ¼”ç¤º:")
        print("  python demos/demo_svraster_training.py")
        print("  python demos/demo_svraster_rendering.py")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æ¼”ç¤ºè„šæœ¬æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
    
    return training_ok and rendering_ok


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
